<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>ngx-smart-table备忘录</title>
      <link href="/2019/10/28/ngx-smart-table%E5%A4%87%E5%BF%98%E5%BD%95/"/>
      <url>/2019/10/28/ngx-smart-table%E5%A4%87%E5%BF%98%E5%BD%95/</url>
      <content type="html"><![CDATA[<h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><p>官网</p><blockquote><p><a href="https://akveo.github.io/ng2-smart-table/" target="_blank" rel="noopener">https://akveo.github.io/ng2-smart-table/</a></p></blockquote><p>github</p><blockquote><p><a href="https://github.com/akveo/ng2-smart-table" target="_blank" rel="noopener">https://github.com/akveo/ng2-smart-table</a></p></blockquote><p>examples</p><blockquote><p><a href="https://github.com/akveo/ng2-smart-table/tree/master/projects/demo/src/app/pages" target="_blank" rel="noopener">https://github.com/akveo/ng2-smart-table/tree/master/projects/demo/src/app/pages</a></p></blockquote><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><pre><code class="typescript">@Component({  selector: &#39;ngx-data&#39;,  template: `&lt;ng2-smart-table [settings]=&quot;settings&quot; [source]=&quot;source&quot;&gt;`,})export class DataComponent {  option:any;  settings = {    pager: {      display: true,      perPage: 50    },    actions: {  //修改ng2-smart-table自带的action列      add: false,        edit: false,      delete: false,    },    hideSubHeader: true, //隐藏顶栏    columns: {      col1: {        title: &#39;值&#39;,        type: &#39;string&#39;,      },      col2: {        title: &#39;更新时间&#39;,        type: &#39;string&#39;,      },    },  };  source: LocalDataSource;  }</code></pre><h1 id="分页器"><a href="#分页器" class="headerlink" title="分页器"></a>分页器</h1><pre><code class="javascript">pager:{    display: true , //是否显示分页器     perPage: 50 //每页显示数量}</code></pre><h2 id="后端分页"><a href="#后端分页" class="headerlink" title="后端分页"></a>后端分页</h2><p>后端分页可以继承<code>LocalDataSource</code>,写一个新的<code>DataSource</code>，重写<code>getElements()</code>和<code>count()</code>函数</p><pre><code class="typescript">export class MyDataSource extends LocalDataSource {  all: number;  devName: string;  namFilter:string;  constructor(private api: MyService) {    super()  }  count(): number {    return this.all;  }  getElements(): Promise&lt;any&gt; {    return this.api.getData(nameFilter).pipe(map(result=&gt;{  //假设返回为{&#39;count&#39;:100,data:[.......]}        this.all = result.count;        return result.data;    })).toPromise();  }}</code></pre><p>使用方式</p><pre><code class="typescript">source:MyDataSource = new DeviceDataSource(this.api);search(name:string){    this.source.nameFilter = name;    this.source.setPage(1);    this.source.refresh();}</code></pre><h1 id="自定义渲染"><a href="#自定义渲染" class="headerlink" title="自定义渲染"></a>自定义渲染</h1><h2 id="方案1"><a href="#方案1" class="headerlink" title="方案1"></a>方案1</h2><pre><code class="javascript">columns: {      col1: {        title: &#39;链接&#39;,        type: &#39;html&#39;,      },}</code></pre><p>直接修改值为html代码</p><h2 id="方案2-自定义渲染器"><a href="#方案2-自定义渲染器" class="headerlink" title="方案2 自定义渲染器"></a>方案2 自定义渲染器</h2><pre><code class="typescript">import {Component, Input, OnInit} from &quot;@angular/core&quot;;import {ViewCell} from &quot;ng2-smart-table&quot;;@Component({  template: `    &lt;button (click)=&quot;onClick()&quot;&gt;{{renderValue}}&lt;/button&gt;  `,})export class CustomRender implements ViewCell, OnInit {  renderValue: string;  @Input() value: string | number; //对应列的值  @Input() rowData: any; //本行所有值:{&#39;col1&#39;:&#39;value1&#39;,&#39;col2&#39;,&#39;value2&#39;}  ngOnInit() {    this.renderValue = value;  }  onClick(){      console.log(rowData);  }}</code></pre><pre><code class="typescript">columns: {      col1: {        title: &#39;链接&#39;,        type: &#39;custom&#39;,        renderComponent: CustomRender      },}</code></pre>]]></content>
      
      
        <tags>
            
            <tag> Angular </tag>
            
            <tag> 备忘录 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如何强上你的邻居</title>
      <link href="/2019/08/31/%E5%A6%82%E4%BD%95%E5%BC%BA%E4%B8%8A%E4%BD%A0%E7%9A%84%E9%82%BB%E5%B1%85/"/>
      <url>/2019/08/31/%E5%A6%82%E4%BD%95%E5%BC%BA%E4%B8%8A%E4%BD%A0%E7%9A%84%E9%82%BB%E5%B1%85/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Wsocks实现了一个很有意思的功能。所以写篇文章分享一下这个功能的一些细节。至于是什么样的功能，<strong>听说过伪造IP吗，朋友</strong>。</p><h1 id="我们的环境"><a href="#我们的环境" class="headerlink" title="我们的环境"></a>我们的环境</h1><p>我做这个测试的服务器地址是：<em>85.143.202.5</em>，一台来自毛子的VPS。</p><blockquote><p>既然用他们的机器搞事情了，那就推广一下作为赔偿吧。<br><a href="https://hexcore.ru" target="_blank" rel="noopener">https://hexcore.ru</a> 最便宜的是225卢布一个月，速度一般，但也还对的起这个价格。而且俄罗斯嘛，能干点别的地方不能干的事情。另外毛子比较耿直，所以年费没有优惠</p></blockquote><p>我的网关是<em>85.143.202.1</em>。我有一个邻居，<em>85.143.202.6</em>，当然我不止这一个邻居。在这里邻居的定义是跟我连在同一个交换机或是hub上的其他“机器”。由于现在都是虚拟服务器，所以这个“机器”的定义就比较模糊了，总之可以理解成其他的vps。</p><p>这个是ARP表</p><blockquote><p>85.143.202.6     f6:96:1e:7f:ce:e1<br>85.143.202.1     a8:d0:e5:54:35:20<br>85.143.202.4     f6:96:cd:84:83:c4         </p></blockquote><h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p>正常来说，我们用85.143.202.5这个IP收发消息，而我们的邻居用它们自己的IP收发消息，一切都很和谐。但是如果有一天，我们要干票大的或是干些什么见不得人的勾当，所以想<strong>借</strong>隔壁兄弟的身份证一用，那要怎么操作呢。<br>这个么，很明显有两种方案。一是闯进邻居的家里，拿走它的身份证，光明正大的去嫖娼，用完之后再还回去。这个方案非常OK，而且已经被沿用了很多年，但是问题就是，总有一天邻居会发现自己的家被人闯了，于是他决定换掉门锁，加固门窗，这样我们就很难再下手了。<br>另一种方式是我们伪造一张邻居的身份证出去招摇撞骗。对于这种方式呢，邻居除了报警之外，他自己是没有任何办法的。而且有可能报警也解决不了问题。</p><h1 id="伪造IP"><a href="#伪造IP" class="headerlink" title="伪造IP"></a>伪造IP</h1><p>在互联网上伪造身份证自然就是<strong>伪造IP</strong>了。玩过黑客的朋友多半听过一个名字——凯文·米特尼克。这位世界第一黑客，曾经就使用过伪造IP来完成攻击。不过虽然都是伪造IP，但是呢，一是凯文当时的年代网络环境简单，二是我们的目标并不是想要攻击谁，所以我们的和凯文之间的操作还是有很大区别的。</p><p>对于我们来说，最终的目标是要能用邻居的IP<strong>收发</strong>消息。为什么要强调<strong>收发</strong>呢，因为<strong>发</strong>其实是一件相对简单的事情，<strong>收</strong>才是整个过程的关键所在。</p><h2 id="用邻居的IP发"><a href="#用邻居的IP发" class="headerlink" title="用邻居的IP发"></a>用邻居的IP发</h2><p>在无论是windows还是linux提供的socket中都有一样叫做<strong>raw socket</strong>的东西。这个东西允许我们自己构造IP头，再构造TCP或是UDP的包，然后内核会不管三七二十一把这个我们自己构造的东西给发出去(<em>Windows似乎在某个版本禁止了使用rawsocket来修改IP，所以要完成这样的操作，还是用Linux吧</em>)。<br>在大多数情况下这个操作是可行的，但是只要稍微分析一下这样的包就会发现这种数据是有漏洞的。<br>我们都知道有个东西叫做<strong>ARP表</strong>，这张表我们有，我们连接着的路由(网关)也有。而这里有个最大的问题就是，所有的数据最后都会通过网关。而聪明一点的网关就会发现，你这个包里的MAC地址和IP咋就对不上呢。于是它有可能会丢掉这个包，或是把这个事件记录到日志里等管理员来看。总之不管是哪种最终都会导致我们的计划受阻。<br>那么最好的方案是什么呢。这里要提一个库<strong>libpcap</strong>，对应的Windows版本是<strong>WinPcap</strong>。pcap这个库可以让我们直接操作网卡发送以太网帧，这样我们可以编辑的就不只是IP了，连source mac都可以一起操作。<strong>需要注意的是，如果要发数据到其他子网，dest mac应该设置成网关的mac地址。</strong><br>放一段使用<code>Pcap4J</code>的代码演示一下这个过程</p><pre><code class="Kotlin">val nif = Pcaps.findAllDevs()[0]val sendHandle = nif.openLive(65536, PcapNetworkInterface.PromiscuousMode.PROMISCUOUS, 10)//用85.143.202.6的IP和MAC发一个UDP包给val udpBuilder = UdpPacket.Builder()    udpBuilder.srcAddr(Inet4Address.getByName(&quot;85.143.202.6&quot;))      .dstAddr(Inet4Address.getByName(&quot;8.8.8.8&quot;))      .srcPort(UdpPort((7777).toShort(), &quot;me&quot;))      .dstPort(UdpPort.DOMAIN) //表示53端口      .correctLengthAtBuild(true)      .correctChecksumAtBuild(true)    val ipV4Builder = IpV4Packet.Builder()      .version(IpVersion.IPV4)      .tos(IpV4Rfc791Tos.newInstance(0.toByte()))      .ttl(100.toByte())      .protocol(IpNumber.UDP)      .srcAddr(Inet4Address.getByName(&quot;85.143.202.6&quot;) as Inet4Address)      .dstAddr(Inet4Address.getByName(&quot;8.8.8.8&quot;) as Inet4Address)      .payloadBuilder(udpBuilder)      .correctChecksumAtBuild(true)      .correctLengthAtBuild(true)    val etherBuilder = EthernetPacket.Builder()    etherBuilder      .dstAddr(MacAddress.getByName(&quot;a8:d0:e5:54:35:20&quot;))      .srcAddr(MacAddress.getByName(&quot;f6:96:1e:7f:ce:e1&quot;))      .type(EtherType.IPV4)      .paddingAtBuild(true)    val ipV4Packet = IpV4Helper.fragment(ipV4Builder.build(), 1200)[0]    etherBuilder.payloadBuilder(      object : AbstractPacket.AbstractBuilder() {        override fun build(): Packet {          return ipV4Packet        }      }).build()      sendHandle.sendPacket(etherBuilder.build())</code></pre><p>OK，这样我们的数据就和正常的流量没有任何区别了。</p><blockquote><p>事实上，如果只是想实现用别人的IP发送数据的话，限制可以小很多。我们一般可以使用整个C类段，甚至是好几个C类段里的IP。这个主要是跟网关的逻辑和虚拟化使用的技术有关。</p></blockquote><h1 id="用邻居的IP收"><a href="#用邻居的IP收" class="headerlink" title="用邻居的IP收"></a>用邻居的IP收</h1><p>发送是一件很简单的事情，但是收就难了。这就好比你寄快递，即使填了个假的发件地址，收件人也还是可以收到邮件的。但是你如果填一个假的收件地址还想让快递小哥把快递送到你家，就很有难度了。</p><h2 id="骗谁"><a href="#骗谁" class="headerlink" title="骗谁"></a>骗谁</h2><p>要想实现这样一个收的操作，就必须要欺骗一些设备了。让我们看看有哪些设备是跟我们有关系的。</p><h3 id="ARP？"><a href="#ARP？" class="headerlink" title="ARP？"></a>ARP？</h3><p>首先是<strong>网关</strong>，发到我们所在的子网的所有数据都会先发到网关那，所以要是能骗网关直接把数据发给我们，那不就万事大吉了。那么这个能做到吗？答案是肯定的。曾有一招从天而降的掌法，如来..呃不，是<em>ARP攻击</em>。就如前面说的，网关它也维护着一张ARP表，里面记录着子网里所有IP和它MAC地址的对应关系。 </p><p>然而ARP这个东西是有漏洞的，我们只要一直给网关发假的ARP响应它就会信以为真把我们的MAC地址和我们邻居的IP地址对应到一块儿去。ARP的技术细节在这里就不多说了，Google一下已经有很多写的很详细的了。  </p><p>那么我们可以用ARP攻击吗？ 很显然不行。首先ARP攻击作为一个古老的攻击方式已经被很多路由器防范了。其次ARP攻击特征明显，很容易被运营商发现，然后把我们给ban了。</p><h3 id="换个傻子"><a href="#换个傻子" class="headerlink" title="换个傻子"></a>换个傻子</h3><p>那么网关不行，网关和我们中间的还有什么呢。这里存在两种情况。  </p><ol><li>我们和我们的邻居连在同一个hub上</li><li>我们和我们的邻居连在同一个交换机上</li></ol><p>如果是hub，那事情就很简单了。众所周知，hub就是个哈皮。它根本不知道连在它身上的都是些什么东西，它只知道自己的哪几个口有东西连上来了。所以一旦有数据发送到了hub这里，它会把这个数据给每个打开的端口(<em>这个端口不是UDP或TCP的端口，而是类似网线接口的那种端口</em>)都发一份。这就等于说邻居收到的数据本来就会给我们发一份，只是平时网卡无视了它。那么我们只要用pcap抓一下包就解决了。  </p><p>而到了交换机上，事情就变得复杂了一点。交换机没这么愚蠢，它内部维护着一张端口和MAC地址的表。一旦有数据到了它这里，它会查看一下数据的目标MAC，然后在自己的对应表里查找对应的端口，并且把数据转发到这个端口。<br>那么这里就有一个问题，交换机是怎么维护这张表的？ 首先交换机只能理解L2的东西，也就是说，不管什么协议的数据经过了交换机，它只在乎源MAC和目标MAC。交换机维护对应表的策略非常简单。查看所有数据的源MAC地址，然后把这个源MAC地址和数据来自的端口对应起来。至于出现了目标MAC地址不在表里的情况，交换机就会像Hub一样广播这个数据。  </p><p>既然交换机是这么维护对应表的，那一切就很明了了。</p><h2 id="欺骗一台交换机"><a href="#欺骗一台交换机" class="headerlink" title="欺骗一台交换机"></a>欺骗一台交换机</h2><p>要骗一台交换机很简单，一个正经的流量就可以欺骗它。我们只需要像前面一样，伪造邻居的IP和MAC随便发点数据就行了。唯一的附加条件是，我们发送的频率要足够高，这样才能够一直抢占邻居的位置。当然了，一旦我们抢占了邻居的位置，那我们的邻居就再也收不到任何数据了。<br>这种方式相对于ARP攻击要更加隐蔽，对于一些老交换机来说甚至是无法被发现的。</p><h1 id="利用"><a href="#利用" class="headerlink" title="利用"></a>利用</h1><p>现在我们有了邻居的公网IP了。<br>对于Wsocks来说，如此折腾了一圈，最终的目的是个自己加点应对GFW的筹码，而且总的看来只是个花里胡哨的把式而已。但是其实这种hack完全可以带来更多的东西，比如类似旁站攻击的操作，或是嫁祸于人的障眼法。要怎么用，还是看最终想要做什么。</p>]]></content>
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> hack </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>C++ Macro,  FUCK YOU!</title>
      <link href="/2019/06/04/C-Macro-FUCK-YOU/"/>
      <url>/2019/06/04/C-Macro-FUCK-YOU/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这几天一直在搞Javafx和Graalvm。主要是Graalvm在Windows上编译native image问题太tm多了。主要问题都出在JNI的部分，现在已经发现有数组访问异常，浮点数传递不正确的bug。要是有人想尝试一下native image在windows上的效果的话，最好先从不涉及jni的库开始。<br>那么，这篇的主题其实跟graalvm没什么关系，开篇只是发个牢骚。当然了，要是没有Graalvm的这些问题，我也不至于把JavaFx的C++实现全给看一遍，也就不会有这篇博客了。</p><h1 id="宏-Macro"><a href="#宏-Macro" class="headerlink" title="宏(Macro)"></a>宏(Macro)</h1><p>虽然我第一次写C++的程序是在2012年，但是其实我的C++是写的很烂的。所以在很长的一段时间里，宏在我的认知里无非是做一些编译期的判断，像是实现DEBUG和RELEASE分支，或是防止头文件被重复引用这样的小事情。唯一跟代码相关的，也就是会把常量定义在宏里。</p><p>因此Graalvm和JavaFx的一些宏操作彻底闪瞎了我的狗眼。先从Graalvm的说起吧。</p><h2 id="Code-Generator-Macro-Version"><a href="#Code-Generator-Macro-Version" class="headerlink" title="Code Generator( Macro Version! )"></a>Code Generator( Macro Version! )</h2><p>代码生成器这种东西各位应该或多或少都接触过。这个东西在Java里可以说是各大框架的杀手锏，你给个接口，他替你实现。在没有宏定义的Java里，框架用各种代码生成工具来实现代码生成，而在C/C++的世界里，代码生成器又可以是什么样子的呢</p><p>先来看一段Graalvm的官方demo</p><pre><code class="C">#include &lt;polyglot.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;struct Point {    double x;    double y;};POLYGLOT_DECLARE_STRUCT(Point)void *allocNativePoint() {    struct Point *ret = malloc(sizeof(*ret));    return polyglot_from_Point(ret);}void *allocNativePointArray(int length) {    struct Point *ret = calloc(length, sizeof(*ret));    return polyglot_from_Point_array(ret, length);}void freeNativePoint(struct Point *p) {    free(p);}void printPoint(struct Point *p) {    printf(&quot;Point&lt;%f,%f&gt;\n&quot;, p-&gt;x, p-&gt;y);}</code></pre><p>实现了什么功能不重要，重要的是其中的<code>POLYGLOT_DECLARE_STRUCT</code>和<code>polyglot_from_Point</code>以及<code>polyglot_from_Point_array</code>这三个东西。</p><p>首先我们可以确定，<code>Point</code>这个东西是我们自己定义的，所以显然这两个带Point的函数也不可能是由<code>polyglot.h</code>提供的。那么为什么在我们也没有定义这两个函数的情况下这段程序可以正常编译呢？这就要靠神奇的(<em>FUCKING UNREADABLE</em>)宏来实现了。</p><p>按照国际惯例(幸好你们还有个国际惯例)宏是全部大写的，所以<code>POLYGLOT_DECLARE_STRUCT</code>就一定是个宏了。于是我在<code>polyglot.h</code>的最底下找到了关于这个的定义。</p><pre><code class="C">#define POLYGLOT_DECLARE_STRUCT(type) __POLYGLOT_DECLARE_GENERIC_TYPE(struct type, type)#define __POLYGLOT_DECLARE_GENERIC_TYPE(typedecl, typename)                                                                                          \  __POLYGLOT_DECLARE_GENERIC_ARRAY(typedecl, typename)                                                                                               \                                                                                                                                                     \  __attribute__((always_inline)) static inline typedecl *polyglot_as_##typename(void *p) {                                                           \    void *ret = polyglot_as_typed(p, polyglot_##typename##_typeid());                                                                                \    return (typedecl *)ret;                                                                                                                          \  }                                                                                                                                                  \                                                                                                                                                     \  __attribute__((always_inline)) static inline void *polyglot_from_##typename(typedecl * s) {                                                        \    return polyglot_from_typed(s, polyglot_##typename##_typeid());                                                                                   \  }  #define __POLYGLOT_DECLARE_GENERIC_ARRAY(typedecl, typename)                                                                                         \  __attribute__((always_inline)) static inline polyglot_typeid polyglot_##typename##_typeid() {                                                      \    static typedecl __polyglot_typeid_##typename[0];                                                                                                 \    return __polyglot_as_typeid(__polyglot_typeid_##typename);                                                                                       \  }                                                                                                                                                  \                                                                                                                                                     \  __attribute__((always_inline)) static inline typedecl *polyglot_as_##typename##_array(void *p) {                                                   \    void *ret = polyglot_as_typed(p, polyglot_array_typeid(polyglot_##typename##_typeid(), 0));                                                      \    return (typedecl *)ret;                                                                                                                          \  }                                                                                                                                                  \                                                                                                                                                     \  __attribute__((always_inline)) static inline void *polyglot_from_##typename##_array(typedecl *arr, uint64_t len) {                                 \    return polyglot_from_typed(arr, polyglot_array_typeid(polyglot_##typename##_typeid(), len));                                                     \  }</code></pre><p>最后发现<code>POLYGLOT_DECLARE_STRUCT(Point)</code>的<code>Point</code>就是宏里的<code>typename</code>。这就破案了，这段宏为我们定义了<code>polyglot_from_##typename</code>和<code>polyglot_from_##typename##_array</code>这两个方法，而其中的<code>typename</code>在编译期就被<code>Point</code>替换掉了（我看你是在为难我IDE）。</p><h2 id="骚气满满的EventBus"><a href="#骚气满满的EventBus" class="headerlink" title="骚气满满的EventBus"></a>骚气满满的EventBus</h2><p>上一个还是很容易理解的，毕竟只是使用了<code>##var</code>这么个特性罢了。不知道的时候觉得很神奇，知道了之后也就是这么一回事。而接下来这个是让我着实惊讶了许久。<br>先看一段代码</p><pre><code class="C++">/* * Class:     com_sun_glass_ui_win_WinWindow * Method:    _setView * Signature: (JJ)Z */JNIEXPORT jboolean JNICALL Java_com_sun_glass_ui_win_WinWindow__1setView    (JNIEnv * env, jobject jThis, jlong ptr, jobject view){    ENTER_MAIN_THREAD()    {        GlassWindow *pWindow = GlassWindow::FromHandle(hWnd);        if (activeTouchWindow == hWnd) {            activeTouchWindow = 0;        }        pWindow-&gt;ResetMouseTracking(hWnd);        pWindow-&gt;SetGlassView(view);        // The condition below may be restricted to WS_POPUP windows        if (::IsWindowVisible(hWnd)) {            pWindow-&gt;NotifyViewSize(hWnd);        }    }    GlassView * view;    LEAVE_MAIN_THREAD_WITH_hWnd;    ARG(view) = view == NULL ? NULL : (GlassView*)env-&gt;GetLongField(view, javaIDs.View.ptr);    PERFORM();    return JNI_TRUE;}</code></pre><p>做过安卓的朋友肯定很熟悉这个套路，修改UI的事情只能在UI线程里做，而对于大部分程序来说UI线程就是主线程，所以这里的<code>ENTER_MAIN_THREAD</code>看着也很正常。</p><p>但是问题来了，这个乍一看很正常的程序，仔细想想怎么都不对劲啊。参数里传进来了一个<code>view</code>，为什么下面还能再声明一个？这个看着很像是函数体的<code>ENTER_MAIN_THREAD()</code>里面的那个<code>hWnd</code>是哪里跑出来的？最底下的<code>ARG</code>和<code>PERFORM</code>这两个又是干嘛的？</p><p>当我第一次意识到这些问题的时候，我甚至开始怀疑这是不是C++的新特性，C++式fp难道是长这个样子的。</p><p>在深入♂了解了之后，我才发现，都是假的。这种漂亮的代码都是假的，是特技，这个世界上根本就没有这种代码。所以现在让我们来看看它是怎么实现的。<br>首先是<code>ENTER_MAIN_THREAD</code>，既然有国际惯例在，那这个东西想必是个宏了</p><pre><code class="C++">#define ENTER_MAIN_THREAD() \    class _MyAction : public Action {    \        public: \                virtual void Do()</code></pre><p>这tm就是它的定义。你可能会说，这tm括号都没闭合呢！是啊，所以它还有下半个，<code>LEAVE_MAIN_THREAD_WITH_hWnd</code></p><pre><code class="C++">#define LEAVE_MAIN_THREAD_WITH_hWnd  \    HWND hWnd;  \     } _action;  \    ARG(hWnd) = (HWND)ptr;</code></pre><p>万万没想到，这几天otto上当了，我也上当了。所以这部分真实情况是长这个样子的</p><pre><code class="C++">class _MyAction:public Action {    public:        virtual void Do()         {            GlassWindow *pWindow = GlassWindow::FromHandle(hWnd);            if (activeTouchWindow == hWnd) {                activeTouchWindow = 0;            }            pWindow-&gt;ResetMouseTracking(hWnd);            pWindow-&gt;SetGlassView(view);            // The condition below may be restricted to WS_POPUP windows            if (::IsWindowVisible(hWnd)) {                pWindow-&gt;NotifyViewSize(hWnd);        }    }    HWND hWnd;    GlassView * view;} _action;ARG(hWnd) = (HWND)ptr;ARG(view) = view == NULL ? NULL : (GlassView*); PERFORM();</code></pre><p>行吧，你还真是<code>Runnable</code>转世到了C++上啊。借着一手宏定义给我整成了lambda的样子。</p><p>到了这里，就只有<code>ARG</code>和<code>PERFORM()</code>还没有解释清楚了。让我们来看看它们两个的定义。</p><pre><code class="C++">#define ARG(var) _action.var#define PERFORM() GlassApplication::ExecAction(&amp;_action)</code></pre><p>于是，最底下这部分就变成了</p><pre><code class="C++">_action.hWnd = (HWND)ptr;_action.view =  view == NULL ? NULL : (GlassView*);GlassApplication::ExecAction(&amp;_action);</code></pre><p>顺便一提，<code>GlassApplication::ExecAction</code>是这样的</p><pre><code class="C++">void GlassApplication::ExecAction(Action *action){    if (!pInstance) {        return;    }    ::SendMessage(pInstance-&gt;GetHWND(), WM_DO_ACTION, (WPARAM)action, (LPARAM)0);}</code></pre><p>搞过Win32编程的朋友一定很熟悉这个东西，没搞过的话理解成在EventBus上发送消息就行了。</p><p>所以到了最后，这个看着像是线程切换的操作只是把<code>_action</code>发送给了主线程而已。高，真的是高。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>宏这个东西真是写者爽翻天，看者流眼泪。这么一想，好像刚开始写C++的时候就有用宏会影响代码可读性这么一说。只是这几年接触C++的少，没见过什么市面，把宏想的太简单了。如今见过这种骚操作之后，我想说，<em>加入光荣的进化吧</em></p>]]></content>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Graalvm native-image JavaFx初体验</title>
      <link href="/2019/06/04/Graalvm%E5%88%9D%E4%BD%93%E9%AA%8C/"/>
      <url>/2019/06/04/Graalvm%E5%88%9D%E4%BD%93%E9%AA%8C/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>尝试了一段时间的Go，发现一是还是舍不得Kotlin，二是Go的UI库实在有点蛋疼，所以最近还是寻找了一些重返Kotlin的解决方案。Graalvm我早有耳闻，也有过一次不愉快的尝试，但是看到它的版本号在今年脱离了RC的标志来到了19.1.1，我决定还是再给它一个机会。</p><h1 id="Graalvm"><a href="#Graalvm" class="headerlink" title="Graalvm"></a>Graalvm</h1><blockquote><p>官网地址: <a href="https://www.graalvm.org/" target="_blank" rel="noopener">https://www.graalvm.org/</a></p></blockquote><p>还是稍微介绍一下<em>Graalvm</em>吧。就目前看来Graalvm算是近年来Oracle最有创造力的产品了。</p><blockquote><p>GraalVM is a universal virtual machine for running applications written in JavaScript, Python, Ruby, R, JVM-based languages like Java, Scala, Groovy, Kotlin, Clojure, and LLVM-based languages such as C and C++.<br>GraalVM removes the isolation between programming languages and enables interoperability in a shared runtime. It can run either standalone or in the context of OpenJDK, Node.js or Oracle Database.</p></blockquote><blockquote><p>Graalvm是一款通用虚拟机，可以运行由Javascript，Python，Ruby，R和基于JVM(Java,Kotlin,Scala,Groovy)以及基于LLVM(C和C++)的语言开发的程序。GraalVM去除了语言之间的隔阂，并且允许它们在运行过程中保持互通。GraalVm既可以独立运行，也可以在OpenJDk，NodeJs或者Oracle数据库的环境中运行(这句话，不明所以)。</p></blockquote><p>以及一些特性</p><ul><li>Polyglot(通用性)<blockquote><p>Zero overhead interoperability between programming languages allows you to write polyglot applications and select the best language for your task.<br>不同语言间无痛交互，根据业务情况任意选择语言</p></blockquote></li><li>Native(原生,这是重点)<blockquote><p>Native images compiled with GraalVM ahead-of-time improve the startup time and reduce the memory footprint of JVM-based applications.<br>GraalVM生成的Native image(可以认为就是可执行文件) 使用AOT技术加快启动时间并且减少基于JVM的应用的启动内存(Java系客户端的两大痛处)</p></blockquote></li><li>Embeddable(嵌入式，不是单片机那个)<blockquote><p>GraalVM can be embedded in both managed and native applications. There are existing integrations into OpenJDK, Node.js and Oracle Database<br>这个Embeddable的特性我还没有接触过，所以并不理解它所说的与OpenJDK这些一起运行是个什么意思</p></blockquote></li></ul><p>GraalVM的这么多特性，对于我来说，最有价值的就是Native了。相信对于大部分Java系的开发者来说也是如此，“我Java系的生态要啥有啥，还要其他语言干嘛？”<br>所以接下来就写一下GraalVM这个不成熟到能跟Kotlin Native 55开的Native image吧。</p><h1 id="Native-image"><a href="#Native-image" class="headerlink" title="Native image"></a>Native image</h1><blockquote><p>官方文档 <a href="https://www.graalvm.org/docs/reference-manual/aot-compilation" target="_blank" rel="noopener">https://www.graalvm.org/docs/reference-manual/aot-compilation</a></p></blockquote><p>话是说的很漂亮，解决了Java写客户端的两大痛处，但是实际用起来那可真全是痛处。当然这里说的痛处是开发中的痛处，在成功build了native image之后，确实是如官网所说，启动速度快，内存占用小(除了莫名其妙的申请了32G虚拟内存)。</p><p>首先一点是，在19.0之后，native-image不再包含在Graal的基础包中了，要安装的话，需要运行个命令</p><blockquote><p>gu install native-image</p></blockquote><p> Linux上这个操作可能需要sudo。文件是从gtihub上下载的，所以国内下载可能会很慢，官网上表示可以配置代理，但是我好像不太成功。总归等了挺久之后也算是下载下来了。</p><p>目前Native image还有很多的限制。按照github上的官方文档，Native image对一些Java的特性还不能支持</p><table><thead><tr><th>特性</th><th>支持情况</th></tr></thead><tbody><tr><td>动态类加载</td><td>不支持</td></tr><tr><td>反射</td><td>需要配置文件</td></tr><tr><td>动态代理</td><td>需要配置文件</td></tr><tr><td>JNI</td><td>大多数支持</td></tr><tr><td>Unsafe Memory Access</td><td>大多数支持</td></tr><tr><td>类初始化(static里初始化类)</td><td>支持</td></tr><tr><td>InvokeDynamic</td><td>不支持</td></tr><tr><td>Lambda Expressions</td><td>支持(有问题)</td></tr><tr><td>Synchronized, wait, and notify</td><td>支持</td></tr><tr><td>Finalizers</td><td>不支持</td></tr><tr><td>References</td><td>大多数支持</td></tr><tr><td>Threads</td><td>支持</td></tr><tr><td>Identity Hash Code</td><td>支持</td></tr><tr><td>Security Manager</td><td>不支持</td></tr><tr><td>JVMTI, JMX, other native VM interfaces</td><td>不支持</td></tr><tr><td>JCA Security Services</td><td>支持</td></tr></tbody></table><p>首先动态类加载肯定是不用想了，native的部分与非native的部分明显不能建立联系。而反射可以通过传入配置文件来获得支持，这就让许多框架的使用成为了可能。</p><h1 id="Native的客户端"><a href="#Native的客户端" class="headerlink" title="Native的客户端"></a>Native的客户端</h1><p>如果只是一个简单的，单线程的console应用，那么native image的使用基本上是不会有任何问题。但是一旦涉及了GUI，这个native image就有点搞人心态了。 </p><p>Java上大家熟知的GUI方案无外乎Swing和Javafx，在graal的issues中可以看到现在尚且不能支持swing，而且由于swing已经是个如此年迈的框架，我也不倾向于使用它。那么现在的选择就只有javafx了。</p><h2 id="JavaFX"><a href="#JavaFX" class="headerlink" title="JavaFX"></a>JavaFX</h2><p>GraalVM有两个版本，一个CE，一个EE，其中CE版是不带JavaFx的。而EE中所带的JavaFx会在编译成native image的过程中出现无数的问题，于是我搜索了graal的issues，并且成功找到了一些前人的经验</p><blockquote><p><a href="https://github.com/oracle/graal/issues/403" target="_blank" rel="noopener">https://github.com/oracle/graal/issues/403</a></p><p><a href="https://github.com/oracle/graal/issues/994" target="_blank" rel="noopener">https://github.com/oracle/graal/issues/994</a></p></blockquote><p><em>其中issue403是Glavo大佬提出的</em></p><p><strong>在 403 的评论中可以看到一个叫做gluonhq的产品</strong>，</p><blockquote><p> <a href="https://github.com/gluonhq/client-samples" target="_blank" rel="noopener">https://github.com/gluonhq/client-samples</a></p></blockquote><p>应该有人通过它成功编译了javafx的native image。我也按照gluonhq的文档做了一些尝试，非常遗憾的是，我并没有成功，失败的原因也不是说出现了什么错误，而是这货占用的内存量有点夸张。几次尝试编译都因为内存不足而告终，后来我曾试图把开发环境搬到生产服务器上(一台16核32G的虚拟服务器)，但最终因为gluonhq不支持windows而宣告失败。所以如果看到这篇文章的人中有不用Windows且内存达到16G的话，可以尝试一下直接使用gluonhq client。</p><p>虽然用gluonhq失败了，但是至少说明已经有人成功了吧。于是我在994中的最后一条评论里找到了这个仓库</p><blockquote><p><a href="https://github.com/maxum2610/HelloJFX-GraalSVM" target="_blank" rel="noopener">https://github.com/maxum2610/HelloJFX-GraalSVM</a></p></blockquote><p>maxum2610表示要构建naive image需要自己build一个OpenJFX。这简直是打开了新世界的大门。既然都自己构建OpenJFX了，那稍微改改代码总也不是什么大事吧。于是参考maxum2610的文档，我开始了自己的旅程。</p><h2 id="OpenJFX"><a href="#OpenJFX" class="headerlink" title="OpenJFX"></a>OpenJFX</h2><p>build OpenJFX的过程中只有遇到了一个问题，这货要求gradle的版本是1.8，然后IDEA默认的是5.1，所以要自己调整一下。</p><p>整个构建的过程是很愉快的，把构建得到的<code>/build/sdk/rt/lib</code>里的文件复制到Graalvm的jre下就可以得到一个自己的JavaFx环境了。接着我开始尝试编译Native image,并且不出意外的失败了。</p><p>报的错误是issue1376中的错误</p><blockquote><p><a href="https://github.com/oracle/graal/issues/1376" target="_blank" rel="noopener">https://github.com/oracle/graal/issues/1376</a></p><p>Invoke with MethodHandle argument could not be reduced to at most a single call: java.lang.invoke.MethodHandleImpl.buildVarargsArray(MethodHandle, MethodHandle, int)</p></blockquote><p>解决方案是把所有报这个错的地方的lambda全部改成java6的语法。</p><p>在全部改完之后就可以成功生成naive image了。当然走到了这步还没有成功。<br>在运行的过程中会发现加载libglass.so失败的问题，一开始我以为是路径有问题，后来发现是在调用JNI_Onload的时候返回了-1。</p><p>于是本着既然都改了源码了，再改点C的代码又怎么样呢的想法，大概看了一下glass_general.cpp中JNI_Onload函数的内容，发现是在加载<code>sun/misc/GThreadHelper</code>的时候报错了，</p><pre><code class="C++">   clazz = env-&gt;FindClass(&quot;sun/misc/GThreadHelper&quot;);   if (env-&gt;ExceptionCheck()) return JNI_ERR;   if (clazz) {       jmethodID mid_getAndSetInitializationNeededFlag = env-&gt;GetStaticMethodID(clazz, &quot;getAndSetInitializationNeededFlag&quot;, &quot;()Z&quot;);       if (env-&gt;ExceptionCheck()) return JNI_ERR;       jmethodID mid_lock = env-&gt;GetStaticMethodID(clazz, &quot;lock&quot;, &quot;()V&quot;);       if (env-&gt;ExceptionCheck()) return JNI_ERR;       jmethodID mid_unlock = env-&gt;GetStaticMethodID(clazz, &quot;unlock&quot;, &quot;()V&quot;);       if (env-&gt;ExceptionCheck()) return JNI_ERR;       env-&gt;CallStaticVoidMethod(clazz, mid_lock);       if (!env-&gt;CallStaticBooleanMethod(clazz, mid_getAndSetInitializationNeededFlag)) {           init_threads();       }       env-&gt;CallStaticVoidMethod(clazz, mid_unlock);   } else {        env-&gt;ExceptionClear();        init_threads();   }</code></pre><p>确认了一下jniconfig，发现确实没有这个库。在搜索了一圈之后决定干脆不加载了，直接走else分支。成功！</p><p>我修改的OpenJFX已经传到github上了</p><blockquote><p> <a href="https://github.com/Wooyme/openjdk-jfx" target="_blank" rel="noopener">https://github.com/Wooyme/openjdk-jfx</a></p></blockquote><p>重新build OpenJFX之后编译出的naive image就可以正常运行了。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Graalvm依然是个很不成熟的技术，要尝试的话就得做好踩坑的觉悟。</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>WSocks疯牛病版技术内幕</title>
      <link href="/2019/04/24/WSocks%E7%96%AF%E7%89%9B%E7%97%85%E7%89%88%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95/"/>
      <url>/2019/04/24/WSocks%E7%96%AF%E7%89%9B%E7%97%85%E7%89%88%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95/</url>
      <content type="html"><![CDATA[<h1 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h1><blockquote><p><a href="https://github.com/Wooyme/Wsocks" target="_blank" rel="noopener">https://github.com/Wooyme/Wsocks</a><br>kcp-raw分支</p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前在LowEndBox上看到一个非常非常便宜的VPS，一年8刀。借着50块买不了吃亏，买不了上当的想法，就随手买了一年。当然，这个机器确实非常垃圾。不过这也很正常，OpenVZ的低价VPS肯定是超售的，而这样便宜的机器要是没有问题才是真的有问题。<br>最开始，我尝试在上面装了一下WSocks2.0，然后发现速度只有几k，基本上就是打开个网页都卡的水平，而且因为是openvz(最坑的是说好的SolusVM到了最后也不知所踪)所以bbr和锐速都上不了，本来是打算就此作罢了。但是无意中看到了几篇关于bbr原理的文章，然后几经周折，被打开了新世界的大门。</p><h1 id="TCP拥塞控制"><a href="#TCP拥塞控制" class="headerlink" title="TCP拥塞控制"></a>TCP拥塞控制</h1><p>装过bbr或者锐速的朋友肯定体验过这两个补丁近乎开挂的速度。尤其是锐速，凭借其更加流氓的算法，能几乎把带宽跑满。那么为什么使用了这些模块之后能让速度更快呢？ 这就要谈到TCP的拥塞控制了。</p><blockquote><p>源自简书 <a href="https://www.jianshu.com/p/97e5d7e73ba0" target="_blank" rel="noopener">https://www.jianshu.com/p/97e5d7e73ba0</a></p></blockquote><blockquote><p>拥塞控制就是防止过多的数据注入到网络中，这样可以防止网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。</p></blockquote><p>那么防止链路过载的方式主要有两种，一是 <strong>慢开始</strong>， 二是 <strong>拥塞避免</strong></p><ul><li>慢开始<blockquote><p>慢开始算法中的主要方法就是有小到大逐渐增大发送窗口。<br>举个例子：首先，发送方设置cwnd=1（为方便理解，这里用报文段的个数作为窗口大小的单位），在收到接收方发来的确认后（也就是下个传输轮次），设置cwnd=2，然后将发送窗口的数据发送出去。在一次收到接收方发来的确认后，发送方设置cwnd=4，再讲发送窗口中的数据发送出去。然后再重复上面的过程。</p></blockquote></li><li>拥塞避免<blockquote><p>TCP/IP 中规定无论是在慢开始阶段还是在拥塞避免阶段，只要发现网络中出现拥塞（没有按时收到确认），就要把ssthresh设置为此时发送窗口的一半大小（不能小于2）。</p></blockquote></li></ul><p>主要的问题在于拥塞避免阶段，常用的拥塞避免算法中，一旦发现超时，窗口大小就会下降的非常快，并且之后上升的速度也会非常慢，于是传输速度就很垃圾了。<br>而bbr和锐速都是修改了这部分算法，让窗口保持在比较大的阶段。当然这种行为本质是流氓行为，不然在Linux 4.10之后的内核中也不会默认关闭bbr。当只有少数人使用的时候，网速会得到非常高的提升，但是一旦大家都用了这种算法，效果也就会趋于平庸了。</p><h1 id="更无耻的UDP"><a href="#更无耻的UDP" class="headerlink" title="更无耻的UDP"></a>更无耻的UDP</h1><p>可是我们的OpenVZ并不能安装bbr或锐速。于是从内核层面修改算法就显得不太现实了。但是除了TCP之外，我们还有一个更加简单的协议可以选择————UDP。<br>UDP是真的很简单，没有流控、没有拥塞控制、也不管数据是否真的传达到了。一旦用了UDP，只管发就是了。当然，简单的背后就是各种的不可靠，无论是丢包或是到达顺序错误都会导致上层出错，这显然是我们不想看到的。于是Google了许久，找到了一个国人开发的UDP Base协议——KCP。</p><blockquote><p>KCP <a href="https://github.com/skywind3000/kcp" target="_blank" rel="noopener">https://github.com/skywind3000/kcp</a></p></blockquote><p>KCP为UDP添加了类似连接的机制，包括连接标识符，ack，窗口，缓冲区等。它让UDP成为了可靠的传输协议。而且由于这些东西都是KCP添加的，所以都不受制于内核，完全可以自己调节。作者就为我们提供了 “极速模式”,实测效果确实很给力，通过开启快速重传、关闭流量控制、调大发送接收窗口，减小mtu，基本可以把服务器带宽压榨干净，而且延迟也确实降低了很多。</p><h1 id="比UDP更无耻"><a href="#比UDP更无耻" class="headerlink" title="比UDP更无耻"></a>比UDP更无耻</h1><p>在实际测试中发现，虽然KCP能达到锐速之类的效果，但是有时候因为ISP的干扰，UDP报文可能会被丢弃。毕竟因为TCP有阻塞控制，把资源分配给TCP会更加合理一些。但是我们既然都已经这么流氓了，再流氓点又如何呢。<br>TCP和UDP在报文上的区别仅仅是报头有些不同，我们完全可以用原始套接字(Raw Socket)自己构造一个TCP报头。这里不得不吹一下KCP的作者，简直就是天才。KCP虽然是以 “Reliable UDP”自诩，但是实际上KCP下层完全可以接任何协议，所以接一个畸形的TCP也是完全没问题的。<br>在KCP的output中，我取了udp2raw_tunnel的部分代码</p><blockquote><p><a href="https://github.com/wangyu-/udp2raw-tunnel" target="_blank" rel="noopener">https://github.com/wangyu-/udp2raw-tunnel</a></p></blockquote><p>让KCP发送的数据变成披着TCP外皮的UDP包。现在只要解决接收的部分，就可以完成客户端与服务端的通信了。这里唯一的问题就是，这种畸形的TCP包，普通的TCP服务端是接收不到的。所以我加入了PCAP</p><blockquote><p>PCAP的java封装 <a href="https://github.com/kaitoy/pcap4j" target="_blank" rel="noopener">https://github.com/kaitoy/pcap4j</a></p></blockquote><p>用于捕获所有从远程服务器的规定端口发送的数据，再把这些数据作为KCP的input传输进去。至此一个基于Raw Socket的KCP协议就完成了。</p><h1 id="Option（伪造IP）"><a href="#Option（伪造IP）" class="headerlink" title="Option（伪造IP）"></a>Option（伪造IP）</h1><p>这里加个题外话。其实也不是题外话，在WSocks的kcp分支里，我实现了一个伪造IP发送UDP包的功能。该功能总的来说就是让服务端用真实的IP接收客户端请求，再从另一个IP发送返回的数据。以前做过一些伪造IP的实验，但都失败了，因为在实际的网络中，各种路由器、网关会检测这个IP是否属于自己包含的范围，如果不是这个包就会被丢掉。所以在公网上想要假装自己是某台机器其实是不现实的。但是如果换一个思路，我们并不需要假装自己是谁，我们只需要让自己不是自己就行了。于是我重新做了些测试，发现在一定范围内，修改IP完全是可行的。在我一台加利福尼亚的VPS上，可供选择的IP多达65535个。通过这种IP伪装的方式，一定程度上也可以保护服务器。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上就是WSocks疯牛病版的一些原理，总的来说就是一个逐渐突破下限的过程。既然想要空手套白狼，那只有比无耻更无耻了。</p>]]></content>
      
      
        <tags>
            
            <tag> Kotlin </tag>
            
            <tag> Vert.x </tag>
            
            <tag> C/C++ </tag>
            
            <tag> 网络协议 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Angular下的Bootstrap Modal</title>
      <link href="/2019/02/18/Angular%E4%B8%8B%E7%9A%84Bootstrap-Modal/"/>
      <url>/2019/02/18/Angular%E4%B8%8B%E7%9A%84Bootstrap-Modal/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Bootstrap有一个Angular的版本——ngx-bootstrap，里面是有提供Boostrap Modal的，但是我一直觉得这种Modal的形式不太好。因为Modal本来就是相对独立在页面之外的，如果要把Modal的代码也写到当前页面里的话其实反而破坏了页面本身的结构。所以我自己封装了一个Modal，写这篇博客记录一下封装的过程。</p><h1 id="Modal-Component"><a href="#Modal-Component" class="headerlink" title="Modal Component"></a>Modal Component</h1><p>不管Modal的html部分写在什么地方，Component都是必需的。</p><pre><code class="html">  &lt;div (click)=&quot;onContainerClicked($event)&quot; class=&quot;modal fade&quot; tabindex=&quot;-1&quot; [ngClass]=&quot;{&#39;in&#39;: visibleAnimate}&quot;       [ngStyle]=&quot;{&#39;display&#39;: visible ? &#39;block&#39; : &#39;none&#39;, &#39;opacity&#39;: visibleAnimate ? 1 : 0}&quot;&gt;    &lt;div class=&quot;modal-dialog&quot;&gt;      &lt;div class=&quot;modal-content&quot;&gt;        &lt;ng-template modal-host&gt;&lt;/ng-template&gt;      &lt;/div&gt;    &lt;/div&gt;  &lt;/div&gt;</code></pre><p>template的部分非常简单。因为我希望Modal的主体是可以自定义的，所以就在里面使用了<code>ng-template</code>标签。</p><pre><code class="Typescript">@Directive({  selector: &#39;[modal-host]&#39;,})export class ModalDirective {  constructor(public viewContainerRef: ViewContainerRef) { }}</code></pre><p>modal-host对应的就是这段代码。<br>接下来就是Modal Component的主体部分了</p><pre><code class="Typescript">export class ModalComponent{  public visible = false;  public visibleAnimate = false;  @ViewChild(ModalDirective) modalHost:ModalDirective;  constructor(private componentFactoryResolver: ComponentFactoryResolver,private modal:ModalService){    this.modal.show.subscribe(value =&gt; {      this.show(value);    })  }  public show(item:ShowItem): void {    //用工厂从component类型里生成component    let componentFactory = this.componentFactoryResolver.resolveComponentFactory(item.component);    let viewContainerRef = this.modalHost.viewContainerRef;    viewContainerRef.clear();    let componentRef = viewContainerRef.createComponent(componentFactory);    (&lt;ModalValue&gt;componentRef.instance).callback = item.callback;    (&lt;ModalValue&gt;componentRef.instance).params = item.params;    let modal = this;    (&lt;ModalValue&gt;componentRef.instance).close = ()=&gt;{modal.hide()};    (&lt;ModalValue&gt;componentRef.instance).onInit();    this.visible = true;    setTimeout(() =&gt; this.visibleAnimate = true, 100);  }  public hide(): void {    this.visibleAnimate = false;    setTimeout(() =&gt; this.visible = false, 300);  }  public onContainerClicked(event: MouseEvent): void {    if ((&lt;HTMLElement&gt;event.target).classList.contains(&#39;modal&#39;)) {      this.hide();    }  }}export interface ModalValue {  callback:(any)=&gt;void;  close:()=&gt;void;  params:any;  onInit();}export class ShowItem{  component:Type&lt;ModalValue&gt;;  callback:(any)=&gt;void;  params:any;  constructor(item:Type&lt;any&gt;,params:any,callback:(any)=&gt;void){    this.component = item;    this.callback = callback;    this.params = params;  }}</code></pre><p>关键部分在<code>show</code>方法里。当从Modal Service(后面会写)里拿到<code>item</code>之后就会调用<code>show</code>方法。首先是拿到新的component，清除之前的component，接着把<code>params</code>，<code>callback</code>注入到component中，调用<code>onInit</code>方法。最后显示Modal。</p><p>Component写完之后需要在app.component.html里给它腾个位置，不然没地方显示。</p><h1 id="Modal-Service"><a href="#Modal-Service" class="headerlink" title="Modal Service"></a>Modal Service</h1><pre><code class="Typescript">@Injectable({  providedIn: &#39;root&#39;})export class ModalService {  show: Observable&lt;ShowItem&gt;;  private showIn: Subject&lt;ShowItem&gt;;  constructor() {    this.showIn = new Subject&lt;ShowItem&gt;();    this.show = this.showIn.asObservable();  }  modal(component:Type&lt;any&gt;,params:any):Promise&lt;any&gt;{    return new Promise((resolve) =&gt; {      this.showIn.next(new ShowItem(component, params, resolve));    })  }}</code></pre><p>Modal Service部分就非常简单了。创建一个<code>Obervable</code>给Modal Component订阅。每当其他地方调用<code>modal</code>方法的时候就会把component类型和参数发布出去。</p><h1 id="使用举例"><a href="#使用举例" class="headerlink" title="使用举例"></a>使用举例</h1><p>以一个非常简单的登出提示框为例</p><pre><code class="Typescript">@Component({  template: `    &lt;div class=&quot;modal-header&quot;&gt;      登出确认    &lt;/div&gt;    &lt;div class=&quot;modal-body&quot;&gt;      &lt;p&gt;是否要退出当前账号&lt;/p&gt;    &lt;/div&gt;    &lt;div class=&quot;modal-footer&quot;&gt;      &lt;button class=&quot;btn btn-primary&quot; (click)=&quot;finish()&quot;&gt;确定&lt;/button&gt;    &lt;/div&gt;  `})export class LogoutEnsure implements ModalValue {  @Input() callback: (any) =&gt; void;  @Input() close: () =&gt; void;  @Input() params: any;  onInit() {  }  finish() {    this.callback({});    this.close();  }}....  logout() {    this.modal.modal(LogoutEnsure, {}).then(() =&gt; {      this.api.getLogout().subscribe(()=&gt;{        this.router.navigate([&#39;/&#39;]);      });    });  }....</code></pre><p>Component只要继承<code>ModalValue</code>就可以在Modal中显示出来。调用modal的时候只要传Component类型即可。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>自己实现一个Modal还是非常简单的。这样可以避免像ngx-bootstrap一样dom节点过深，而且代码结构也更加美观。</p>]]></content>
      
      
        <tags>
            
            <tag> Angular </tag>
            
            <tag> Typescript </tag>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>川叔的Ubuntu私房菜（2333</title>
      <link href="/2019/02/12/%E5%B7%9D%E5%8F%94%E7%9A%84Ubuntu%E7%A7%81%E6%88%BF%E8%8F%9C%EF%BC%882333/"/>
      <url>/2019/02/12/%E5%B7%9D%E5%8F%94%E7%9A%84Ubuntu%E7%A7%81%E6%88%BF%E8%8F%9C%EF%BC%882333/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><strong>本篇针对Ubuntu18.04或Ubuntu Gnome</strong><br>推荐一本书《鸟哥的Linux私房菜》，虽然我没有看完，但真的是一本很棒的书。由于鸟哥的Linux写的非常深入，所以对于不做运维的人来说有些太难了。<br>这篇《川叔的Ubuntu私房菜》就作为我记录各种在使用Ubuntu时学到的小技巧的地方。<strong>顺便一提利根川赛高</strong>。</p><h1 id="SCP-不是基金会"><a href="#SCP-不是基金会" class="headerlink" title="SCP (不是基金会)"></a>SCP (不是基金会)</h1><blockquote><p>Linux之间传文件有除了ftp外更简单的方式</p></blockquote><p>不知道为什么，每次在服务器上装vsftpd都是一件非常痛苦的事情，总会遇到各种奇奇怪怪的问题。以至于后来有一段时间，我甚至选择使用网盘、github这种第三方存储作为上传文件到服务器的媒介。<br>这种情况终止于一天逛<strong>Ubuntu Forums</strong>的时候发现有人用</p><pre><code class="bash">scp xxx root@xxx:/home/xxx</code></pre><p>的命令。查了一下才知道，这就是基于ssh的文件上传。</p><pre><code>usage: scp [-346BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file]           [-l limit] [-o ssh_option] [-P port] [-S program]           [[user@]host1:]file1 ... [[user@]host2:]file2</code></pre><p>example</p><pre><code class="bash">scp this.zip root@my.server.com:/home/www/this.zip</code></pre><p>要注意的是目录需要提前建好，不然会报<em>没有找到目录或文件</em>的错。</p><h1 id="kill-9-PID-amp-xkill"><a href="#kill-9-PID-amp-xkill" class="headerlink" title="kill -9 PID &amp; xkill"></a>kill -9 PID &amp; xkill</h1><p>有时会遇到执行了<code>kill PID</code>但是进程还是杀不死的情况。这个时候加上<code>-9</code>参数就可以杀死进程了。<br>另外在桌面端的时候有时候会遇到Chrome、QQ、LibreOffice卡死的情况，这个时候可以<code>Ctrl+Alt+T</code>打开终端输入<code>xkill</code>,然后鼠标就会变成一个”x”，点一下卡死的窗口就可以关掉了。顺便一提的是有时候Ubuntu会弹出系统崩溃、系统错误这样的对话框，实际上其中只有很小一部分是真正的系统崩溃，大部分都是某个软件崩溃了，具体内容可以展开详情看看。</p><h1 id="QQ-amp-TIM"><a href="#QQ-amp-TIM" class="headerlink" title="QQ &amp; TIM"></a>QQ &amp; TIM</h1><p>由于腾讯压根就没有提供Linux的版本所以在Ubuntu上用QQ是一个比较麻烦的事情。Github上有很多QQ for Linux的项目，但是其实最终都指向了一个唯一的解决方案——<code>Wine</code>。  </p><blockquote><p>说个冷知识，<code>Wine</code>的全称是<code>Wine Is Not an Emulator</code></p></blockquote><p>Wine给在Linux、Mac上运行Windows程序提供了可能。虽然各种奇怪的bug和内存泄露是经常的事，但是有总比没有好。不过呢如果真的要从安装Wine、安装各种.Net库、字体开始到最终安装QQ、TIM，那也太麻烦了。比较简单的是去Github上找已经打成<code>AppImage</code>的发行版，但是还有一种更通用、更稳定的方法——<code>Crossover</code>。</p><p><code>Crossover</code>是一款商业软件、所以是收费的，终身是100多，不想付的话网上也应该能找到破解版。</p><blockquote><p>官网 <a href="http://www.crossoverchina.com/goumai.html?lid=1984" target="_blank" rel="noopener">http://www.crossoverchina.com/goumai.html?lid=1984</a></p></blockquote><p>装了<code>Crossover</code>之后安装Windows上的程序就完全傻瓜化了，而且会有各种软件在Linux上兼容性的评分。QQ和TIM间建议安装TIM，QQ有时候会突然崩溃，比较僵硬。</p><h1 id="系统监视器-任务管理器"><a href="#系统监视器-任务管理器" class="headerlink" title="系统监视器(任务管理器)"></a>系统监视器(任务管理器)</h1><p>Ubuntu是有个类似于任务管理器的东西的，只不过Gnome并没有为他绑定快捷键，如果想要像Windows一样使用任务管理器的话需要在<code>设置</code>-&gt;<code>设备</code>-&gt;<code>键盘</code>里添加。系统监视器对应的命令是<code>gnome-system-monitor</code></p><h1 id="美化桌面"><a href="#美化桌面" class="headerlink" title="美化桌面"></a>美化桌面</h1><p>虽然18.04换了Gnome，但是完完全全的继承了原本Unity的丑。看看隔壁<code>Kali</code>的桌面，帅到爆。再看看Ubuntu，开机基佬紫就不说了，桌面侧边栏真是丑到没话说。<br>首先要安装<code>User Themes</code>，</p><blockquote><p><a href="https://extensions.gnome.org/extension/19/user-themes/" target="_blank" rel="noopener">https://extensions.gnome.org/extension/19/user-themes/</a></p></blockquote><p>为了更方便的安装插件、需要在Chrome中先安装<code>extensions.gnome.org</code>的插件。</p><p>安装好User Themes后(最好再装一个<code>dash to dock</code>或者<code>dash to panel</code>)就可以到gnome-look里挑一个中意的主题了。</p><blockquote><p><a href="https://www.gnome-look.org" target="_blank" rel="noopener">https://www.gnome-look.org</a></p></blockquote><p>主题的作者一般会在下载的地方写好安装方法。</p><h1 id="美化登录"><a href="#美化登录" class="headerlink" title="美化登录"></a>美化登录</h1><p>如果说桌面还可以接受的话、那登录界面真是人神共愤了。不过好在gnome-look里一样提供了很多gdm的主题。我个人比较推荐这个</p><blockquote><p><a href="https://www.gnome-look.org/p/1241489/" target="_blank" rel="noopener">https://www.gnome-look.org/p/1241489/</a></p></blockquote><p>作者的README写的也非常清楚</p><blockquote><p>复制bg-boat.jpg到背景目录<br>cp ~/Downloads/Ocean-blue-GDM3/bg-boat.jpg /usr/share/backgrounds/</p><p>备份默认的ubuntu.css<br>cp /usr/share/gnome-shell/theme/ubuntu.css /usr/share/gnome-shell/theme/ubuntu.bk</p><p>覆盖ubuntu.css<br>cp ~/Downloads/Ocean-blue-GDM3/ubuntu.css /usr/share/gnome-shell/theme/</p><p>重启<br>reboot -f</p></blockquote>]]></content>
      
      
        <tags>
            
            <tag> 杂谈 </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Vert.x后端漫游指南(4)</title>
      <link href="/2019/01/17/Vert-x%E5%90%8E%E7%AB%AF%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8D%97-4/"/>
      <url>/2019/01/17/Vert-x%E5%90%8E%E7%AB%AF%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8D%97-4/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>非常非常久没有更新 <em>Vert.x后端漫游指南</em> 了。主要是因为之前觉得Vert.x的Web后端实在是没有什么好写的，都是一些常规操作。再者，也有很长一段时间没有碰Vert.x的后端开发了。但是呢，因为打算做一个Vert.x全栈的服务端应用，所以又把Web后端的部分拿出来了。</p><h1 id="API？"><a href="#API？" class="headerlink" title="API？"></a>API？</h1><p>虽然Vertx-Web也支持模板引擎这类的东西，但是无论是从潮流还是从Vertx支持程度的角度来看，前后端分离的开发方式更加适合现在的Web开发。那么既然前后端分离，提供一套完整、合理的API就非常重要了。<br>回顾一下之前的 <em>Vert.x后端漫游指南</em> ,我们使用了<code>Router.route(&quot;/api/path&quot;)</code>的方式来设置API。这种方式非常的简单粗暴，没有注解，没有配置文件，完完全全的硬编码。对于单人开发的简单服务来说，这样当然是没有问题的。但是当有了开发团队，需要前后端沟通的时候，这种硬编码的方式就变得很麻烦了。<br>一方面这意味着还得再单独写一份API文档给前端，</p><blockquote><p>程序员最讨厌两种事情，一是没有文档，二是写文档。</p></blockquote><p>另一方面是一旦要做什么修改，就必须要重新编译程序。  </p><h1 id="Swagger-amp-OpenAPI"><a href="#Swagger-amp-OpenAPI" class="headerlink" title="Swagger &amp; OpenAPI"></a>Swagger &amp; OpenAPI</h1><blockquote><p>Swagger <a href="https://swagger.io/" target="_blank" rel="noopener">https://swagger.io/</a></p></blockquote><blockquote><p>OpenApi <a href="https://www.openapis.org/" target="_blank" rel="noopener">https://www.openapis.org/</a></p></blockquote><p>OpenAPI和Swagger给API开发带来了不一样的体验。Swagger是一套非常完善的API开发工具，最新的版本已经提供了对OpenAPI 3.0 的支持。</p><h2 id="yaml"><a href="#yaml" class="headerlink" title="yaml"></a>yaml</h2><p>Swagger使用yaml作为配置文件，</p><pre><code class="yaml">openapi: 3.0.0info:    title: Sample API    description: Optional multiline or single-line description in [CommonMark](http://commonmark.org/help/) or HTML.    version: 0.1.9servers:  - url: /v1    description: Optional server description, e.g. Main (production) server  - url: http://staging-api.example.com    description: Optional server description, e.g. Internal staging server for testing    paths:    /api/transactions/{id}:        get:            operationId: getTransactionsList            parameters:                -   name: id                    in: path                    required: true                    schema:                        type: string                     -   name: from                    in: query                    required: false                    schema:                        type: string                -   name: to                    in: query                    required: false                    schema:                        type: string            responses:                 200:                    content:                        application/json:                            schema:                                type: object        put:            operationId: putTransaction            parameters:                -   name: id                    in: path                    required: true                    schema:                        type: string            requestBody:                required: true                content:                    application/json:                        schema:                            type: object                            properties:                                from:                                    type: string                                    format: email                                to:                                    type: string                                    format: email                                value:                                    type: number                                    format: double                            additionalProperties: false                            required:                                - from                                - to                                - value            responses: ...</code></pre><p>大致上就是这个样子,详细的关于swagger中yaml配置的编写可以看官方文档</p><blockquote><p><a href="https://swagger.io/docs/specification/basic-structure/" target="_blank" rel="noopener">https://swagger.io/docs/specification/basic-structure/</a></p></blockquote><p>总体来说就是把原来的硬编码改成了文件配置的模式。通过<code>paths</code>和<code>get</code>,<code>put</code>,<code>post</code>,<code>delete</code>一起组成各种API，同时也通过<code>parameters</code>和<code>requestBody</code>规定了各个API所需的参数，以及最后的<code>responses</code>用于规定服务端返回的数据结构。  </p><h2 id="Swagger-Codegen"><a href="#Swagger-Codegen" class="headerlink" title="Swagger-Codegen"></a>Swagger-Codegen</h2><p>有了配置文件之后当然还是要能够生成对应的代码才行。Swagger提供了Swagger-Codegen来生成各种语言、框架的服务端和客户端代码。</p><blockquote><p><a href="https://github.com/swagger-api/swagger-codegen" target="_blank" rel="noopener">https://github.com/swagger-api/swagger-codegen</a></p></blockquote><p>如果要使用<strong>OpenAPI 3.0</strong>的话就必须要安装3.0.0版本以上的Swagger-Codegen。目前由于这个工具还在频繁的更新中，所以bug也是挺多的，特别是在客户端代码的部分，前几天就遇到生成的<code>typescript-angular</code>的代码里没有把body放到<code>post</code>和<code>put</code>的参数里的问题。<br>如果开发的时候遇到了不可理喻的问题，就去issues里看看吧。</p><h1 id="Vert-x的Web-API-Contract"><a href="#Vert-x的Web-API-Contract" class="headerlink" title="Vert.x的Web API Contract"></a>Vert.x的Web API Contract</h1><p>在写完Swagger之后呢，就要来看看Vert.x的Web API Contract了。为什么明明有Swagger了，Vert.x的团队还要搞个Contract呢，因为<strong>Swagger不支持Vert.x</strong>( 笑 。Swagger虽然已经支持很多主流框架了，但是很明显Vert.x还不是那么的”主流”。</p><blockquote><p>官方文档 <a href="https://vertx.io/docs/vertx-web-api-contract/java/" target="_blank" rel="noopener">https://vertx.io/docs/vertx-web-api-contract/java/</a></p></blockquote><h2 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h2><p>Maven</p><pre><code class="xml">&lt;dependency&gt; &lt;groupId&gt;io.vertx&lt;/groupId&gt; &lt;artifactId&gt;vertx-web-api-contract&lt;/artifactId&gt; &lt;version&gt;3.6.2&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>Gradle</p><pre><code class="Groovy">dependencies { compile &#39;io.vertx:vertx-web-api-contract:3.6.2&#39;}</code></pre><h2 id="创建一个工厂"><a href="#创建一个工厂" class="headerlink" title="创建一个工厂"></a>创建一个工厂</h2><pre><code class="Java">OpenAPI3RouterFactory.create(vertx, &quot;yaml的路径,支持本地文件或是http、https的地址&quot;, ar -&gt; {  if (ar.succeeded()) {    //得到了一个路由工厂    OpenAPI3RouterFactory routerFactory = ar.result();  } else {    Throwable exception = ar.cause();  }});</code></pre><p>得到这样一个工厂之后，就可以添加各种处理器</p><pre><code class="Java">routerFactory.addHandlerByOperationId(&quot;awesomeOperation&quot;, routingContext -&gt; {  RequestParameters params = routingContext.get(&quot;parsedParameters&quot;);  RequestParameter body = params.body();  JsonObject jsonBody = body.getJsonObject();  // Do something with body});routerFactory.addFailureHandlerByOperationId(&quot;awesomeOperation&quot;, routingContext -&gt; {  // Handle failure});</code></pre><p>这里的<code>OperationId</code>就对应了yaml文件中的<code>OperationId</code>，对于需要做权限控制的路由，还可以添加<code>Security Handler</code></p><pre><code class="Java">routerFactory.addSecurityHandler(&quot;security_scheme_name&quot;, securityHandler);</code></pre><p>对于之前我们用到的SessionHandler、CookieHandler，可以通过调用<code>addGlobalHandler</code>的方式来添加。需要注意的是BodyHandler不能用<code>addGlobalHandler</code>，<code>OpenAPI3RouterFactory</code>为它提供了专门的方法。</p><p>在添加完处理器之后，就可以生产路由了</p><pre><code class="Java">Router router = routerFactory.getRouter();HttpServer server = vertx.createHttpServer(new HttpServerOptions().setPort(8080).setHost(&quot;localhost&quot;));server.requestHandler(router).listen();</code></pre><p>这部分跟之前相差无几，唯一要注意的是<code>router::accept</code>已经被弃用了，现在直接向<code>requestHandler</code>传递<code>router</code>就可以了。</p><h1 id="Vert-x的Web-API-Service"><a href="#Vert-x的Web-API-Service" class="headerlink" title="Vert.x的Web API Service"></a>Vert.x的Web API Service</h1><blockquote><p>Contract之后再来个Service是要干什么。</p></blockquote><p>各位肯定也都发现了，Web API Contract用起来是一点都不方便，先不说每个处理器都要通过<code>operationId</code>单独绑定，就说处理器得到的参数吧，一点都不智能，完全没有用到Yaml中配置的<code>parameters</code>，参数还是要像以前一样从<code>RoutingContext</code>里获取。<br>为了获得更好的开发体验，就必须要引入Web API Service了。</p><blockquote><p>官方文档 <a href="https://vertx.io/docs/vertx-web-api-service/java/" target="_blank" rel="noopener">https://vertx.io/docs/vertx-web-api-service/java/</a></p></blockquote><h2 id="构建-1"><a href="#构建-1" class="headerlink" title="构建"></a>构建</h2><p>Maven</p><pre><code class="xml">&lt;dependency&gt; &lt;groupId&gt;io.vertx&lt;/groupId&gt; &lt;artifactId&gt;vertx-codegen&lt;/artifactId&gt; &lt;version&gt;3.6.2&lt;/version&gt; &lt;classifier&gt;processor&lt;/classifier&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.vertx&lt;/groupId&gt; &lt;artifactId&gt;vertx-web-api-service&lt;/artifactId&gt; &lt;version&gt;3.6.2&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>Gradle</p><pre><code class="Groovy">dependencies { compile &#39;io.vertx:vertx-codegen:3.6.2:processor&#39; compile &#39;io.vertx:vertx-web-api-service:3.6.2&#39;}</code></pre><p>可以看到，除了<code>vertx-web-api-service</code>以外，还引入了<code>vertx-codegen</code>。在codegen面前，没有什么问题是解决不了的。</p><h2 id="使用Interface"><a href="#使用Interface" class="headerlink" title="使用Interface"></a>使用Interface</h2><pre><code class="Java">@WebApiServiceGeninterface TransactionService { void getTransactionsList(String from, String to, OperationRequest context, Handler&lt;AsyncResult&lt;OperationResponse&gt;&gt; resultHandler); void putTransaction(JsonObject body, OperationRequest context, Handler&lt;AsyncResult&lt;OperationResponse&gt;&gt; resultHandler);}</code></pre><p>Web API Service提供了另一种绑定handler的方式。接口中的方法名称需要和<code>operationId</code>相同，其中的参数也需要和<code>parameters</code>相同，需要注意的是如果使用<code>requestBody</code>，则对应<code>JsonObject body</code>。最后的<code>OperationRequest context</code>和<code>Handler&lt;AsyncResult&lt;OperationResponse&gt;&gt; resultHandler</code>是必须写的部分。分别代表了请求的额外信息和响应的对象。</p><ul><li>OperationRequest<ul><li>getHeaders 请求头信息</li><li>getParams 请求参数</li><li>getUser 如果使用Auth，User就在这里</li><li>getExtra 可以通过向RouterFactory添加<code>setExtraOperationContextPayloadMapper</code>来<strong>额外设置extra</strong>，这个很重要,通过这种方式可以把session带到handler里来。</li></ul></li><li>OperationResponses<ul><li>响应头</li><li>响应状态</li><li>响应主体</li></ul></li></ul><h2 id="添加Service到RouterFactory"><a href="#添加Service到RouterFactory" class="headerlink" title="添加Service到RouterFactory"></a>添加Service到RouterFactory</h2><pre><code class="Kotlin">OpenAPI3RouterFactory.create(vertx,&quot;yaml文件路径&quot;){    val serviceImpl = ServiceImpl()    ServiceBinder(vertx)        .setAddress(&quot;my-service&quot;)        .register(Service::class.java,ServiceImpl)    it.result().mountServiceInterface(Service::class.java,&quot;my-service&quot;)    //因为Web API Contract并不会处理yaml中的servers，所以需要自己设置sub-router    val router = Router.router(vertx).mountSubRouter(&quot;/api&quot;,it.result().router)    vertx.createHttpServer().requestHandler(router).listen(80){        logger.info(&quot;Listen at 80&quot;)    }    }</code></pre><p>这样就可以非常方便的使用Vert.x的Web API Service了。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>在使用了OpenAPI之后，Vert.x的后端开发就算是比较完整了。这种开发方式也能给前端开发提供很多便利，比硬编码的模式要更加适合现在的开发形式。</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Kotlin Native求生指南(3)</title>
      <link href="/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-3/"/>
      <url>/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-3/</url>
      <content type="html"><![CDATA[<h1 id="上一篇地址"><a href="#上一篇地址" class="headerlink" title="上一篇地址"></a>上一篇地址</h1><blockquote><p><a href="https://wooyme.github.io/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-2/">https://wooyme.github.io/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-2/</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>上一篇意外的花了整篇的篇幅写<em>cinterop</em>,INTEROP的文档比我想的要长太多。那么这一篇就来写一下Kotlin Native的多线程模型。由于Kotlin Native还在频繁更新中，所以多线程API和注解还是有可能出现较大变化的，本篇文章针对的是<strong>Kotlin Native v0.9</strong>,其他版本如有差异，请忽略这篇文章，以官方为准。</p><blockquote><p><a href="https://github.com/JetBrains/kotlin-native/blob/master/CONCURRENCY.md" target="_blank" rel="noopener">https://github.com/JetBrains/kotlin-native/blob/master/CONCURRENCY.md</a></p></blockquote><p>并且这篇文章只讲Kotlin Native的多线程模型，并不涉及协程，想要了解协程的朋友，还是看官方的文档吧。</p><h1 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h1><p>可能说到多线程，我们马上就会想到<code>pthread</code>之类的东西。没错<code>pthread</code>作为<strong>POSIX</strong>提供的跨平台多线程API可以说是非常深入人心了。你问我Kotlin Native支不支持<code>pthread</code>,那肯定是支持的，我们完全可以像在C/C++中做的那样，通过<code>pthread</code>创建新的线程，只是要在线程启动的时候运行一下<code>kotlin.native.initRuntimeIfNeeded()</code>。<br>但是，实际上Kotlin Native给我们提供了一个更好的选择——<strong>Worker</strong>。让我们来看看官方对Worker的介绍</p><blockquote><p>不同于线程的是，Kotlin Native引入了Worker这个概念:能够并行处理请求队列的控制流(concurrently executed control flow streams with an associated request queue)。Workers与Actor模型中的Actor很像，一个Worker可以与其他Worker交换数据。<strong>在任何时候可变的对象只会被一个Worker拥有</strong>。</p></blockquote><p>好像不是很好理解，我们看官方给的例子</p><pre><code class="Kotlin">package sample.workersimport kotlin.native.concurrent.*data class WorkerArgument(val intParam: Int, val stringParam: String)data class WorkerResult(val intResult: Int, val stringResult: String)fun main() {    val COUNT = 5    //创建5个Worker对象    val workers = Array(COUNT, { _ -&gt; Worker.start() })    for (attempt in 1..3) {        val futures = Array(workers.size) { workerIndex -&gt;            workers[workerIndex].execute(TransferMode.SAFE, {                //传入要给Worker处理的参数                WorkerArgument(workerIndex, &quot;attempt $attempt&quot;)            }) { input -&gt;                //Worker处理参数                var sum = 0                for (i in 0..input.intParam * 1000) {                    sum += i                }                WorkerResult(sum, input.stringParam + &quot; result&quot;)            }        }        val futureSet = futures.toSet()        var consumed = 0        while (consumed &lt; futureSet.size) {            //等待运行结束的Workers            val ready = waitForMultipleFutures(futureSet, 10000)            ready.forEach {                //处理Worker的运行结果                it.consume { result -&gt;                    if (result.stringResult != &quot;attempt $attempt result&quot;) throw Error(&quot;Unexpected $result&quot;)                    consumed++                }            }        }    }    workers.forEach {        //终止Worker        it.requestTermination().result    }    println(&quot;Workers: OK&quot;)}</code></pre><p>这就是一个通过创建多个Workers来并行处理数据的例子。可以看到跟Actor模型还挺像的。在<code>Worker.execute</code>的第一个参数里传入生成待处理数据的lambda，然后在第二个参数里传入处理数据的lambda。然后在需要的时候调用<code>future.consume</code>,传入处理结果的lambda。这一切看上去跟Java上的许多异步框架别无二致，但实际上。。。。后面会讲到其中的坑爹之处。  </p><h1 id="全局变量和单例"><a href="#全局变量和单例" class="headerlink" title="全局变量和单例"></a>全局变量和单例</h1><blockquote><p>虽然Worker和线程的实现方式并不相同，但是行为类似，所以后面就不严格区分Worker和线程了</p></blockquote><p>在线程间共享数据最简单的方法就是全局变量了，但同时全局变量也是导致多线程出现各种问题的罪魁祸首。于是Kotlin Native引入了一系列的限制措施来保证全局变量不会影响Worker模型的工作。</p><ul><li>除非添加了特殊的注解，不然全局变量只能在主线程中被访问，如果其他线程试图访问这个变量会报<code>IncorrectDereferenceException</code>异常</li><li>一个添加了<code>@ThreadLocal</code>的全局变量会在每个线程里复制一份，所以每个线程都是独享这个变量的，<strong>某个线程对变量的改动对其他线程不可见</strong></li><li>一个添加了@SharedImmutable的变量是能在线程间共享的，但是<strong>它会被冻结</strong>，后续如果程序尝试修改这个变量也是会抛出异常的。需要注意的是，这个冻结不受<code>var</code>或是<code>val</code>的影响，就算声明的时候是<code>var</code>的只要冻结了就不能再被修改了。同时需要注意的是，<strong>一个被冻结的变量是不能被解冻的</strong></li><li>对于单例(objects)，<strong>除非添加@ThreadLocal注解,不然会被冻结从而可以在线程间共享</strong>。对于其中的属性，lazy是被允许的。</li></ul><p>相信对于从JVM转过来的人来说，我们还是习惯写单例而不是全局变量。就算是保存一个全局变量，也还是习惯于放在一个单例里作为单例的属性。于是坑就出现了。</p><pre><code class="Kotlin">object Foo{    lateinit var A:String    init{        //某些操作....        A = ......    }    fun foo(){        //某些操作.....        A = .....    }}</code></pre><p>根据上面的规则，猜猜看结果会是什么样吧。我想大部分人都会认为<code>init</code>中对A的赋值应该是可以的，至于<code>foo</code>中的赋值则要看是在哪个线程里执行了。但事实是，两个都不行，无论什么情况都不行。即使A是<code>lateinit</code>的，只要Foo被<code>frozen</code>了，里面的属性就不能再被修改。Kotlin Native是真的很严格，就算我们自始至终只有一个主线程也不行。所以<code>object</code>几乎是必须加上<code>@ThreadLocal</code>注解。<br>但是加上<code>@ThreadLocal</code>真的就能解决问题了吗，规则里说，加上<code>@ThreadLocal</code>的变量会在每个线程间复制一份，不知道你们是怎么理解的，反正我最开始看到这端话的时候觉得这个<em>复制</em>应该会在<em>新的线程创建的时候把创建这个线程的线程中的变量复制到新的线程上</em>。举个例子</p><pre><code class="Kotlin">@ThreadLocalobject Foo{    var A:String? = null}fun main(){    Foo.A = &quot;Hello&quot;    Worker.start().execute(Transport.SAFE,{}){        println(Foo.A)    }.consume{}}//我期望的输出Hello//实际上的输出null</code></pre><blockquote><p>这谁顶得住啊</p></blockquote><p>总之就是被Kotlin Native的文档秀了一脸。它说的复制，就是保证其他线程上也有一个叫做<code>Foo</code>的单例。而单例里面是什么则完全取决于它初始化完了是什么。这简直是颠覆了我对多线程的认识。那么正确的做法是什么呢。</p><pre><code class="Kotlin">@ThreadLocalobject Foo{    var A:String? = null}fun main(){    Foo.A = &quot;Hello&quot;    Worker.start().execute(Transport.SAFE,{        Foo.A    }){ str-&gt;        Foo.A = str        println(Foo.A)    }.consume{}}</code></pre><p><code>execute</code>的第一个lambada参数就给我们用来干这个事情的，这是唯一一个能让其他线程与主线程产生联系的地方。我们需要在这里把想要<em>复制</em>的值传到子线程，然后在子线程里做<em>粘贴</em>的工作。  </p><h1 id="共享可变量"><a href="#共享可变量" class="headerlink" title="共享可变量"></a>共享可变量</h1><p>但是这样的<em>复制</em>很明显是不够的，比如说我想在Worker里运行一个Event Loop，我必然要在Worker运行的时候向它传递一些数据。于是这个时候就必须要跳出Kotlin Native的管理，寻求C的帮助了。<br>虽然Kotlin的变量在线程间是独立的，但是通过<code>nativeHeap.alloc</code>分配的内存在线程间依然是共享的。所以我们就可以写出这样的代码</p><pre><code class="Kotlin">fun main(){    val ptr = nativeHeap.allocArray&lt;ByteVar&gt;(10)    memScope{        memcpy(ptr,&quot;A&quot;.cstr.ptr,&quot;A&quot;.cstr.size)    }    val future = Worker.start().execute(Transport.SAFE,{        ptr    }){ _ptr-&gt;        while(true){            println(_ptr.toKString())            sleep(100)        }    }    sleep(100)    memScope{        memcpy(ptr,&quot;B&quot;.cstr,ptr,&quot;B&quot;.cstr.size)    }    future.consume{}}</code></pre><p>通过这种方法就可以在线程间共享可变的变量了。当然这和传统的多线程模型一样，如果设计不当依然会导致各种多线程中常见的问题。<br>这样的共享方式是比较原始的，毕竟我们共享的是最原始的数据，如果想要共享一个对象的话，就需要使用<code>Object subgraph detachment</code></p><blockquote><p>一个没有外部引用的对象子图可以通过<code>DetachedObjectGraph&lt;T&gt;</code>解除连接(disconnected)变成一个<code>COpaquePointer</code>从而存储在C的结构体中，接着可以在任意的线程或Worker中通过<code>DetachedObjectGraph&lt;T&gt;.attach()</code>重新连接得到这个对象子图。</p></blockquote><p>配合前面的方法，就可以在线程间共享对象了。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>Kotlin Native的多线程模型就如Kotlin的空安全机制一样，可以说是为了解决传统多线程中的问题做出了许多设计上的规范，但是为了应对一些特殊的情况，这种规范也是要做出让步的，这种时候还是得我们自己来注意多线程间的问题。<br>那么至此，Kotlin Native的系列就算是结束了。基本上把我在做KN开发时候遇到的一些坑都写在里面了，要说体验如何的话，一是资料太少了，官方的又只有英文，有些是它没说清楚，有些是我理解有差，导致了许多莫名其妙的问题。二是库太少了，整个github上，关于Kotlin Native的库只有两个，一个是只有IOS版本的Ktor，另一个是libui的Kotlin Native Binding，而且好久没有更新了。三是太依赖C语言了，没点C/C++开发基础还真搞不定。<br>总之Kotlin Native作为一个连1.0版本都没到的语言(姑且叫它语言吧)，能用它写出一个还算像样的工具已经是挺不错的。相信只要JetBrains没有放弃KN，KN应该也会成为一门像Go一样大众的语言。</p>]]></content>
      
      
        <tags>
            
            <tag> Kotlin </tag>
            
            <tag> Native </tag>
            
            <tag> C </tag>
            
            <tag> 多线程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kotlin Native求生指南(2)</title>
      <link href="/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-2/"/>
      <url>/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-2/</url>
      <content type="html"><![CDATA[<h1 id="上一篇地址"><a href="#上一篇地址" class="headerlink" title="上一篇地址"></a>上一篇地址</h1><blockquote><p><a href="https://wooyme.github.io/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-1/">https://wooyme.github.io/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-1/</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在<strong>Kotlin Native求生指南1</strong>中我们已经提到了KN的内存模型和GC。那么在本篇中，我们将一起了解一下KN的<em>Cinterop</em>。</p><h1 id="Cinterop"><a href="#Cinterop" class="headerlink" title="Cinterop"></a>Cinterop</h1><p>由于Kotlin Native内置的库实在是太少了，我们不得不大量依赖C的库，于是<em>Cinterop</em>就诞生了。<em>Cinterop</em>的作用就是把C的库翻译成可供Kotlin使用的<em>klib</em>。需要注意的是，现在Cinterop只支持C语言的库。不过实际上只要提供的头文件是C语言的即可，具体实现还是可以使用C++。</p><h2 id="Gradle"><a href="#Gradle" class="headerlink" title="Gradle"></a>Gradle</h2><p>要使用Cinterop需要修改一下Gradle。</p><pre><code class="Groovy">kotlin {    targets {        fromPreset(presets.linuxX64, &#39;linux&#39;)        configure([linux]) {            compilations.main.outputKinds(&#39;EXECUTABLE&#39;)            compilations.main.entryPoint = &#39;main&#39;            //我添加的代码            compilations.main{                cinterops {                    //包名称，需要与.def文件名对应,也可以增加一个参数修改def文件位置，一般不需要                    libui {                        packageName &#39;libui&#39;                    }                }            }        }    }}</code></pre><p>修改好gradle之后，应该就可以看到<code>interop/cinteropLibuiLinux</code>命令</p><h2 id="def"><a href="#def" class="headerlink" title="def"></a>def</h2><p>.def文件需要放在<code>src/nativeInterop/cinterop</code>里，并且要与gradle中的包名相同。比如这里就应该是<code>libui.def</code>。现在让我们来看看.def文件中应该是什么样的</p><pre><code class="bash">#如果涉及到多个文件，都用空格隔开#设置头文件位置headers=/usr/include/ui.h#包名package=libui#静态库文件名staticLibraries = libui.a#静态库路径libraryPaths = /home/wooyme/Projects/libui/build/out</code></pre><p>这样的.def文件是针对静态库使用的，如果要用动态链接库则需要改成下面这样</p><pre><code class="bash">#如果涉及到多个文件，都用空格隔开#设置头文件位置headers=/usr/include/ui.h#包名package=libui//编译选项，供编译器clang使用compilerOpts.linux= -I/usr/include///链接选项，供链接器ldd使用linkerOpts.linux = -L/usr/lib/x86_64-linux-gnu -lui</code></pre><p>动态链接库的使用要比静态库更加复杂一点，其实就是开发C/C++经常会用到的这些参数，在linux上，我们可以使用<strong>pkg-config</strong>来获得这些参数,以libui为例</p><pre><code class="bash">pkg-config --cflags --libs libui</code></pre><p>然后<strong>pkg-config</strong>就会打印相应参数，非常的方便。<br>一切都配置完之后，就只需要运行一下<code>interop/cinteropLibuiLinux</code>就可以了。</p><h2 id="使用Interop"><a href="#使用Interop" class="headerlink" title="使用Interop"></a>使用Interop</h2><p>完成了上面的操作之后，就可以看到IDEA的<code>External libraries</code>里多了<code>xxx-cinterop-libui.klib</code>，里面就是从C语言转换过来的Kotlin Native Library。你可能会去试图打开里面的内容，看看都转换出了什么东西，但事实是你只能看到一堆被注释标记着的，莫名其妙的代码。<br><strong>不要试图去看Cinterop转换后的knm文件</strong>，如果想了解库中提供了哪些函数的话，正确的做法是去看原始的C语言头文件。  </p><p>下面我翻一下 Kotlin Native 在 github 上的 INTEROP.md </p><blockquote><p>原文<br><a href="https://github.com/JetBrains/kotlin-native/blob/master/INTEROP.md" target="_blank" rel="noopener">https://github.com/JetBrains/kotlin-native/blob/master/INTEROP.md</a></p></blockquote><h3 id="基础类型"><a href="#基础类型" class="headerlink" title="基础类型"></a>基础类型</h3><p>所有支持的C类型都会被转换成Kolin 类型</p><ul><li>有符号、无符号整形和浮点型都会被转换到Kotlin上，并且保持相同的长度</li><li>指针和数组会被转换成CPointer<t>?</t></li><li>枚举类型可以根据def文件配置转换成Kotlin的枚举类或是整形</li><li>结构体会被转换成对应的类</li><li>typedef会被转换成typealias</li></ul><p>这里还有一段很难翻译，它引入了一个左值(<code>lvalue</code>),大意是Cinterop会给这些转换过来的类型加一个<code>${type}Var</code>,然后可以通过<code>${type}Var.value</code>调用这个类型本身的值，就像C++的Reference</p><h3 id="指针类型"><a href="#指针类型" class="headerlink" title="指针类型"></a>指针类型</h3><p>CPointer<t>的T必须是上述左值之一，比如说<code>struct S*</code>对应<code>CPointer&lt;S&gt;</code>,<code>int8_t*</code>对应<code>CPointer&lt;int8_tVar&gt;</code>,<code>char**</code>对应<code>CPointer&lt;CPointerVar&lt;ByteVar&gt;</code><br>C语言的空指针，对应Kotlin的null, <code>CPointer&lt;T&gt;</code>可以使用所有kotlin的空安全操作<code>？:</code>,<code>?.</code>,<code>!!</code>等。比如</t></p><pre><code class="Kotlin">val path = getenv(&quot;PATH&quot;)?.toKString() ?: &quot;&quot;</code></pre><p>由于数组也被转换成<code>CPointer&lt;T&gt;</code>,所以<code>CPointer&lt;T&gt;</code>也支持<code>[]</code>操作,比如</p><pre><code class="Kotlin">fun shift(ptr: CPointer&lt;BytePtr&gt;, length: Int) {    for (index in 0 .. length - 2) {        ptr[index] = ptr[index + 1]    }}</code></pre><p><code>CPointer&lt;T&gt;</code>的<code>.pointed</code>属性返回T,比如说<code>CPointer&lt;ByteVar&gt;</code>就返回<code>ByteVar</code>，而<code>ByteVar</code>就是就是<code>Byte</code>的左值，然后可以通过<code>ByteVar.value</code>得到这个<code>Byte</code>。左值又可以通过<code>.ptr</code>得到对应的<code>CPointer&lt;T&gt;</code><br><code>void*</code>对应<code>COpaquePointer</code>,这是所有其他指针类型的父类，所以如果一个C函数的参数是<code>void*</code>，Kotlin中可以给他传任何<code>CPointer</code><br>指针类型转换可以使用<code>.reinterop&lt;T&gt;</code>,比如</p><pre><code class="Kotlin">val intPtr = bytePtr.reinterpret&lt;IntVar&gt;()//或val intPtr: CPointer&lt;IntVar&gt; = bytePtr.reinterpret()</code></pre><p>这个跟C语言里的强制转换是一样不安全的。<br>同样的，<code>CPointer&lt;T&gt;</code>也可以通过<code>.toLong()</code>和<code>.toCPointer&lt;T&gt;</code>与<code>Long</code>互相转换,当然这也是不安全的。</p><h3 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h3><p>内存可以通过使用<code>NativePlacement</code>接口分配,如</p><pre><code class="Kotlin">val byteVar = placement.alloc&lt;ByteVar&gt;()//或val bytePtr = placement.allocArray&lt;ByteVar&gt;(5)</code></pre><p>最常用的是<code>nativeHeap</code>,它就和<code>malloc</code>与<code>free</code>一样</p><pre><code class="Kotlin">val buffer = nativeHeap.allocArray&lt;ByteVar&gt;(size)//use buffer.....nativeHeap.free(buffer)</code></pre><p>除此之外还可以使用<code>memScope</code>，我们在前一篇已经写过，这里就不再赘述。</p><h3 id="传递指针"><a href="#传递指针" class="headerlink" title="传递指针"></a>传递指针</h3><p>虽然C语言的指针对应的是<code>CPointer&lt;T&gt;</code>，但是C语言的函数中的指针参数对应的是<code>CValuesRef&lt;T&gt;</code>。当我们传入的参数是<code>CPointer&lt;T&gt;</code>时，一切都很正常，但是除了<code>CPointer&lt;T&gt;</code>，我们还可以传别的东西。设计<code>CValuesRef&lt;T&gt;</code>就是为了能够让我们在向函数传递数组的时候不需要显式分配一块内存，Kotlin为我们提供了这些方法。</p><ul><li>${type}Array.toCValues(), type是Kotlin的基本类型</li><li>Array&lt;CPointer&lt; T &gt;?&gt;.toCValues(), List&lt;CPointer&lt; T &gt;?&gt;.toCValues()</li><li>cValuesOf(vararg elements: ${type}), type是基本类型或者指针</li></ul><p>比如可以这么写</p><pre><code class="C">//C语言void foo(int* elements, int count);...int elements[] = {1, 2, 3};foo(elements, 3);</code></pre><pre><code class="Kotlin">//Kotlinfoo(cValuesOf(1, 2, 3), 3)</code></pre><h3 id="关于字符串"><a href="#关于字符串" class="headerlink" title="关于字符串"></a>关于字符串</h3><p>不同于其他的指针，<code>const char*</code>被转换成Kotlin的String。除此之外，还有其他的一些工具可以让Kotlin的String与C语言的<code>const char*</code>进行转换</p><ul><li>fun CPointer&lt; ByteVar &gt;.toKString(): String</li><li>val String.cstr: CValuesRef&lt; ByteVar &gt;<br>要得到<code>.cstr</code>的指针，需要给<code>cstr</code>分配内存,比如<pre><code class="Kotlin">//官方这里是这么写的，但是不知道为什么我这里不行，我只能在memScope里调用.cstr.ptrval cString = kotlinString.cstr.getPointer(nativeHeap)//我的版本memScope{    val cString = kotlinString.cstr.ptr}</code></pre>在所有情况下，C语言的string都可以使用UTF-8编码<br>如果不想要使用<code>const char*</code>到<code>String</code>的自动转换，可以在def文件里设置<pre><code>noStringConversion = LoadCursorA LoadCursorW</code></pre>调用LoadCursorA，LoadCursorW就变成了这样<pre><code class="Kotlin">memScoped {  LoadCursorA(null, &quot;cursor.bmp&quot;.cstr.ptr)   // for ASCII version  LoadCursorW(null, &quot;cursor.bmp&quot;.wcstr.ptr)  // for Unicode version}</code></pre><h3 id="传递、接收结构体"><a href="#传递、接收结构体" class="headerlink" title="传递、接收结构体"></a>传递、接收结构体</h3><em>这个其实不是很重要，因为大部分成熟一点的C的库都不会直接把结构体本身作为参数或是返回值,所以我就直接跳过了，关于这一段的原文也不长</em></li></ul><h3 id="回调函数"><a href="#回调函数" class="headerlink" title="回调函数"></a>回调函数</h3><p>要把Kotlin的函数变成C语言的函数指针需要使用<code>staticCFunction(::kotlinFunction)</code>,<code>staticCFunction</code>也接受<strong>lambda</strong>作为参数，顺便一提，<code>staticCFunction</code>依然继承了Kotlin的暴力美学，就像最初的40+参数的lambda一样。这里要注意的是，这个lambda必须是<em>静态</em>的，也就是不能用闭包，不能用<em>class</em>内的值，而且现在<code>staticCFunction</code>有个bug，不能直接使用<code>object</code>内的方法</p><pre><code class="Kotlin">object A{    fun foo(){}}//这样不行staticCFunction(A::foo)//这样OKstaticCFunction{    A.foo()}</code></pre><p>如果callback没有运行在主线程里，那么就需要在callback开头加上<code>kotlin.native.initRuntimeIfNeeded()</code>,初始化Kotlin Native环境，这一点和Kotlin Native的多线程模型有关系。</p><h4 id="向callback传递数据"><a href="#向callback传递数据" class="headerlink" title="向callback传递数据"></a>向callback传递数据</h4><p>由于callback不能使用闭包这类的操作，传递参数就很重要了。大多数的C API都允许用户向callback传递一些指针，但是Kotlin的类并不能直接传递给C，所以就需要一些操作把类转换成指针。</p><pre><code class="Kotlin">val stableRef = StableRef.create(kotlinReference)val voidPtr = stableRef.asCPointer()</code></pre><p>把指针转换成Kotlin类</p><pre><code class="Kotlin">val stableRef = voidPtr.asStableRef&lt;KotlinClass&gt;()val kotlinReference = stableRef.get()</code></pre><p>这样两者的转换就完成了，要注意的是,创建的<code>stableRef</code>需要用<code>.dispose()</code>手动释放，以防止内存泄露。</p><h3 id="可移植性"><a href="#可移植性" class="headerlink" title="可移植性"></a>可移植性</h3><p>大意就是提供了一个<code>.convert&lt;T&gt;()</code>方法，能把基本类型转换成C函数需要的类型，跟<code>.toShort()</code>,<code>toUInt()</code>等方法有相同的作用。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>我实在是没想到一个<em>Cinterop</em>可以写这么长，本来还想在这一篇里把KN的<em>多线程模型</em>给写了，这么看来还是再写第三篇好了。这里稍微说一下我的<em>Cinterop</em>使用体验，总的来说就是功能实现的很完善了，但是用户体验真的很烂。其实最大的问题就是Kotlin是一门OOP的语言，但是C语言不是。其实很多C语言的库都有OOP的影子，无论是命名方式还是那些函数与Kotlin扩展函数别无二致的第一个参数，如果KN的<em>Cinterop</em>能够更加智能一点的话应该会有更好的体验。<br>这一点，我也在Kotlin Native的github上提了issue，官方表示会考虑通过在def中增加一些选项的方式来修改<em>Cinterop</em>的行为</p><blockquote><p><a href="https://github.com/JetBrains/kotlin-native/issues/2486" target="_blank" rel="noopener">https://github.com/JetBrains/kotlin-native/issues/2486</a></p></blockquote><p>Kotlin Native，路途还很漫长</p>]]></content>
      
      
        <tags>
            
            <tag> Kotlin </tag>
            
            <tag> Native </tag>
            
            <tag> C </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kotlin Native求生指南(1)</title>
      <link href="/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-1/"/>
      <url>/2018/12/22/Kotlin-Native%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-1/</url>
      <content type="html"><![CDATA[<h1 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h1><blockquote><p><a href="https://github.com/Wooyme/Wsocks-Naitve-Client" target="_blank" rel="noopener">https://github.com/Wooyme/Wsocks-Naitve-Client</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote><p>C++是一门好语言，Go也是一门好语言，Kotlin Native不是。</p></blockquote><p>首先确定一个观点，写Kotlin-JVM不一定要很懂Java，比如我自己。但是写Kotlin-Native要是不懂C，那就等着吃屎吧。Kotlin Native不是一个让我们跳过C语言走上Native开发道路的神器，至少现在不是。如果你想要Native又不想学C有关的东西的话，选Go吧，我能在这里列举1000个Go的优点和0个缺点。如果一定要说Go有什么缺点的话，那就只能是程序崩溃的时候Go打印的栈信息不能像Java那样漂亮。<br>当然Kotlin Native也不是一无是处，至少它可以督促我再复习一遍C语言的知识。 </p><h1 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h1><p>现在IDEA和CLION都可以支持Kotlin Native的开发。这个项目我用的是IDEA和Gradle，在开发这个项目之前我也用过CLION和Cmake的组合，要做个比较的话，还是Gradle更加适合我们这些从Kotlin-JVM转过来的玩家，毕竟对于不熟悉Cmake的人来说，看看别人写的CmakeList就已经够头疼的了，更何况要自己写。<br>顺便一提，我是在Ubuntu18.04上开发的。Windows和Linux上开发可能会有比较大的差异，还是推荐Windows上装一下Cygwin，能一定程度上减小这个差异。</p><h1 id="第一个工-小-程-坑"><a href="#第一个工-小-程-坑" class="headerlink" title="第一个工(小)程(坑)"></a>第一个工(小)程(坑)</h1><p>从IDEA里创建一个工程是很容易的。不过我遇到了一个小坑，IDEA创完工程之后会出现kt文件打不开的情况，应对的办法是<code>File-&gt;Invalidate Cache/Restart...</code><br>从这第一个坑开始，我们就踏上了Kotlin Native的漫漫坑爹路。工程创建之后会有一个默认的文件，里面是个hello world，我们编译运行一下。编译这个过程只能从Gradle里执行，在<code>other</code>里<code>runProgram</code>，顺利的话Hello World就就会成功打印出来。这里应该不会遇到什么问题，Gradle会智能的下载KN的编译器，只是可能会有点慢。</p><h2 id="我能干什么"><a href="#我能干什么" class="headerlink" title="我能干什么"></a>我能干什么</h2><p>爬过第一个坑之后，你可能迫不及待的想写点什么，比如来一个文件IO，你可能会习惯性的写一个<code>File</code>然后等待IDEA的语法提示，但是令人失望的是，IDEA除了把你的<code>File</code>标记为红色以外什么都不会做。然后你也许还会试一试其他你在JVM里经常用的类，但是它们多半没有，除了<code>StringBuilder</code>这个SB，它还是依然坚挺。<br>这个时候你可能才意识到，大清亡了，世界变了，原来的那些小伙伴都不在了。剩下的只有少的可怜的<em>Kotlin标准库</em>和陌生的<em>stdlib</em>、<em>posix</em>、<em>win32</em>或者<em>linux</em>、<em>darwin</em>以及我至今不能理解为什么要放在默认支持库里的<em>zlib</em>(我觉得唯一的可能就是JetBrains的人想试试cinterop好不好用)。</p><h2 id="认清现实"><a href="#认清现实" class="headerlink" title="认清现实"></a>认清现实</h2><p>好了，既然之前的都用不了了，那就不得不重新开始。让我们来看一看Kotlin Native的文件操作应该是什么样的。</p><pre><code class="Kotlin">//读取一个完整的文件，保存到String中fun main(){    val fp = fopen(myHome+&quot;save.json&quot;, &quot;r&quot;) ?: return println(&quot;Cannot open&quot;)    val fileStat = nativeHeap.alloc&lt;stat&gt;()    stat(myHome+&quot;save.json&quot;,fileStat.ptr)    val size = fileStat.st_size.toInt()+1    val bytes = nativeHeap.allocArray&lt;ByteVar&gt;(size)    fread(bytes,size.toULong(),size.toULong(),fp)    val text = bytes.toKString()    nativeHeap.free(fileStat.ptr)    fclose(fp)}</code></pre><p>OK,先说明一下，官方的例程里很少使用nativeHeap，它们比较喜欢用memScope{}，这两个的区别我会在之后说明。现在先让我们看完这段代码。相信如果你还记得C语言的东西的话，你肯定会说:”这tm不就是C吗”。没错，这tm就是Kotlin版C语言。Old fashion的<code>fopen</code>，<code>stat</code>，<code>fread</code>，当然这一切都无可厚非，毕竟Native的世界和Java的世界本来就大相径庭。我们也可以自己动手封装一个File类出来，我也相信Jetbrains会在某一个版本把这些基本的工具加入到Kotlin Native的标准库中去的。<br>除开C的部分，还是有些东西值得我们关注的，比如刚刚说的<code>nativeHeap</code>，以及一个有趣的方法——<code>toKString()</code>。这个方法真的可以说是Kotlin Native最后的仁慈了。我们知道Kotlin的String和C的const char<em> 是两个完全不同的体系。String类里有记录String长度的部分，好让我们知道String在什么位置结束，但是const char</em> 不同，它依赖结尾处的<code>0x00</code>来判断字符串是否结束。于是这里Kotlin Native很<strong>贴心</strong>的为我们加入了<code>toKString()</code>和<code>String.cstr</code>来保证两者间的转换。</p><h1 id="nativeHeap和memScope？"><a href="#nativeHeap和memScope？" class="headerlink" title="nativeHeap和memScope？"></a>nativeHeap和memScope？</h1><blockquote><p>参考资料 <a href="https://resources.jetbrains.com/storage/products/kotlinconf2018/slides/5_Kotlin-Native%20concurrency%20and%20memory%20model%20(1).pdf" target="_blank" rel="noopener">https://resources.jetbrains.com/storage/products/kotlinconf2018/slides/5_Kotlin-Native%20concurrency%20and%20memory%20model%20(1).pdf</a></p></blockquote><p>有一点是我们必须要知道的，那就是Kotlin Native是有GC的。在Kotlin自己的世界里，GC是隐藏在代码之下的，就像java一样，它们用引用计数法(<em>Simple local reference-counter based algorithm</em>)、”试图删除法”(<em>Cycle collector based on the trial deletion</em>)等算法保证GC的工作。但是由于Kotlin Native提供的东西实在是太少了，我们不得不依赖很多<em>C library</em>,于是手动分配内存就成了不可避免的事情。<br>手动内存管理是场噩梦，这个道理让最顽固的C++也被迫妥协，从析构到现在的智能指针，C++可以说是做了许多让步了。毫无疑问，Kotlin也是懂这个道理的。于是JetBrains推出了memScope这个东西。</p><h2 id="memScope"><a href="#memScope" class="headerlink" title="memScope"></a>memScope</h2><p>memScope的作用是当memScope的作用域结束的时候，自动释放在里面分配的所有内存，以刚才的例子来说</p><pre><code class="Kotlin">val bytes = nativeHeap.allocArray&lt;ByteVar&gt;(size)</code></pre><p>应该写成</p><pre><code class="Kotlin">val text = memScope{    val bytes = nativeHeap.allocArray&lt;ByteVar&gt;(size)    fread(bytes,size.toULong(),size.toULong(),fp)    bytes.toKString()}</code></pre><p>这样当memScope结束的时候，bytes就被自动释放了，而text则是通过<code>toKString()</code>方法实例化的一个String类，可以被KN自己的GC机制回收。所以这段代码不会导致任何内存泄露。除此之外还有很多方法是需要在memScope中才能执行的，比如说<code>CValues&lt;T&gt;.ptr</code>这是用来获取CValues的指针，关于这个稍微说一下我的看法,ptr的getter应该是<em>重新分配</em>了一块内存，然后把CValues中的值<em>复制</em>了进去，因此才需要在memScope中执行，以保证内存不会泄露，不过这又导致了一个新的坑，我在之后会提到。</p><h2 id="nativeHeap"><a href="#nativeHeap" class="headerlink" title="nativeHeap"></a>nativeHeap</h2><p>那为什么我们还需要nativeHeap这样的方式来分配内存呢。还是举个例子吧。</p><pre><code class="Kotlin">fun foo() {    val mgr = nativeHeap.alloc&lt;mg_mgr&gt;().ptr    mg_mgr_init(mgr, null)    while (flag) {        mg_mgr_poll(_mgr, 100)    }    mg_mgr_free(mgr)}</code></pre><p>mg是一个C的网络库，我们启动了一个事件循环来处理各种网络请求。可以看到，这个库自带了一个释放函数<code>mg_mgr_free</code>,被<code>mg_mgr_init</code>初始化过的内存应该由这个库本身来释放。如果我们把代码写成下面这样</p><pre><code class="Kotlin">fun foo() {    memScope{        val mgr = alloc&lt;mg_mgr&gt;().ptr        mg_mgr_init(mgr, null)        while (flag) {            mg_mgr_poll(_mgr, 100)        }        mg_mgr_free(mgr)    }}</code></pre><p>那么在循环终止，程序运行完<code>mg_mgr_free</code>之后很有可能就会因为<code>double free</code>而<em>崩溃</em>。其实我也不是很理解为什么一块内存不能释放两次，或者应该说free为什么不能对同一块内存执行两次，就算已经释放了，给我返回个false也好，何必搞个崩溃呢。总之这也算是刚开始写KN时很容易遇到的一个坑。</p><h2 id="内存管理导致的坑"><a href="#内存管理导致的坑" class="headerlink" title="内存管理导致的坑"></a>内存管理导致的坑</h2><p>在我的工程里，遇到了这么个情况。我有一个系统托盘的功能，里面有一些菜单元素也就是Item，这些Item都是要显示一些字，图标之类的，当然还有回调，每次菜单变化的时候都需要调用一个<code>update</code>函数，这个函数的执行过程实际上就是重新初始化一个整个菜单。<br>最初我的代码是这样的</p><pre><code class="Kotlin">val tray = nativeHeap.alloc&lt;tray&gt;()fun init(){    //设成2是因为tray的C实现需要以空为结尾    val menus = nativeHeap.allocArray&lt;tray_menu&gt;(2)    memScope{        menus[0].text = &quot;设置&quot;.cstr.ptr        //staticCFunction看名字就能知道是为了提供C语言中的&quot;函数指针&quot;        menus[0].cb = staticCFunction { _ -&gt;            //balabalabalabala            tray_update(tray.ptr)        }        tray.menu = menus        tray_init(tray.ptr)    }}</code></pre><p>代码看上去没什么问题，启动的时候也没什么问题，但是当运行<code>menus[0]</code>的<code>callback</code>执行的时候问题就来了。update之后”设置“这两个字变成了乱码，而罪魁祸首就是memScope。memScope在作用域结束的时候释放掉了<code>&quot;设置&quot;.cstr.ptr</code>这个指针(ptr)对应的内存，也就是说在<code>tray_init</code>之后<code>menus[0].text</code>已经是个野指针了。于是当我们执行<code>tray_update</code>的时候，这块内存会是什么样子已经不是我们能够控制的了。于是，我被迫写出了这样的代码</p><pre><code class="Kotlin">val tray = nativeHeap.alloc&lt;tray&gt;()fun init(){    //设成2是因为tray的C实现需要以空为结尾    val menus = nativeHeap.allocArray&lt;tray_menu&gt;(2)    val text = &quot;设置&quot;.cstr    val textPtr = nativeHeap.allocArray&lt;ByteVar&gt;(text.size)    memScope{        //把内存复制到不会被自动释放的地方        memcpy(textPtr,text.ptr,text.size.toULong())    }    menus[0].text = textPtr    menus[0].cb = staticCFunction { _ -&gt;            //balabalabalabala            tray_update(tray.ptr)        }        tray.menu = menus        tray_init(tray.ptr)}</code></pre><p>这只能说是很傻逼了,可能KN提供了一些更加优雅的方式只是我不知道。但总之Kotlin Native的<code>memScope</code>在某些情况下是会与C产生冲突的，而且这种问题往往很隐蔽，这也就是为什么野指针会成为困扰C/C++这么久的问题。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>OK，去掉代码大概有3000个字了。<br>第一篇就先到此为止，大概写了一下我对Kotlin Native的看法和对它内存模型的认识以及使用中遇到的几个坑。下一篇会应该会写一下Cinterop，和Kotlin Native的多线程模型。KN的多线程对于初学者来说也是个神坑，就没见过这样的线程模型，而且文档也比较含糊，不过毕竟还在频繁更新，很多东西变的太快了，文档也确实比较难写。</p>]]></content>
      
      
        <tags>
            
            <tag> Kotlin </tag>
            
            <tag> Native </tag>
            
            <tag> C </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>自己动手写Ss</title>
      <link href="/2018/12/16/%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%86%99Ss/"/>
      <url>/2018/12/16/%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%86%99Ss/</url>
      <content type="html"><![CDATA[<h1 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h1><blockquote><p><a href="https://github.com/Wooyme/Wsocks" target="_blank" rel="noopener">https://github.com/Wooyme/Wsocks</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近VPN不太太平，无论是商业的还是自己租服务器私建的，都或多或少有些遭众。据说是GFW进行了一波升级，但是我个人还是觉得，它只是又更新了一轮黑名单。总之不管怎么样，最近的科学上网是不太稳当了。<br>一周前，我用了一年的服务器遭到了封禁。一时间大有一种大难临头的感觉，再加上各种流言蜚语，于是决定自己来做一个代理工具。</p><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>用过SS的应该都知道SS由两个部分组成——<strong>客户端</strong>与<strong>服务端</strong>。<strong>客户端</strong>往往运行着一个Socks5代理，能够从浏览器之类的程序获取请求，然后<em>加密</em>发送到<strong>服务端</strong>，<strong>服务端</strong>收到请求后，<em>解密</em>再发送给真正的<strong>目标服务器</strong>并监听<strong>目标服务器</strong>的返回，得到返回后再<em>加密</em>发送给<strong>客户端</strong>，<strong>客户端</strong>再<em>解密</em>后发送给浏览器。  </p><blockquote><p>浏览器 –(明文)–&gt; 客户端 –(密文)–&gt; 服务端 –(明文)–&gt; 目标服务器<br>目标服务器 –(明文)–&gt; 服务端 –(密文)–&gt; 客户端 –(明文)–&gt; 浏览器</p></blockquote><p>整体流程其实非常简单，只是因为有加解密的过程，显得有些繁琐。</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>要实现这样一个代理，核心是解决客户端与服务端之间的交互。实现这个交互的方式有很多种，无论是直接基于UDP，UTP，TCP这样的底层协议开发，还是使用HTTP，WebSocket这样应用层的协议都是可行的。<strong>这里我们使用WebSoket协议作为客户端与服务端之间的交互协议</strong></p><h2 id="1-Why-websocket"><a href="#1-Why-websocket" class="headerlink" title="1.Why websocket ?"></a>1.Why websocket ?</h2><ul><li>第一，基于WebSocket的开发实在是太简单了。Websocket作为一个被各大浏览器，以及服务端框架支持的协议，其封装实在是太完善了。使用这些封装好的库，我们就不用考虑TCP协议中会遇到的粘包，UDP中的丢包问题。</li><li>第二，Websocket可以把我们的代理程序伪装成一个站点，因为这是网页与后端间常用的协议，已经被许多社交网站，视频网站，页游使用，所以显得更加正常。</li><li>第三，相较于HTTP这样的应用层协议，websocket占用的资源还是要更小一些的，毕竟我们自己用来跑代理的服务器往往配置不会那么高，资源能省则省。</li></ul><h2 id="2-How-to-do"><a href="#2-How-to-do" class="headerlink" title="2.How to do ?"></a>2.How to do ?</h2><p>基于Websocket的开发是非常简单的，当然前提是得有个够给劲的框架。按照我的博客的惯例，这篇文章，不出意外的会使用Vert.x和Kotlin作为技术栈(笑。顺便说一下，在GC，Cache等参数设置得当的情况下，是可以很大程度上降低JVM的内存占用量的。JVM的许多默认设置都是拿内存换CPU，所以会显得java程序很占内存。<br>那么先贴一段Demo</p><pre><code class="Kotlin">class ServerWebSocket:AbstractVerticle() {    private val logger = LoggerFactory.getLogger(ServerWebSocket::class.java)    private lateinit var netClient: NetClient    private lateinit var httpServer:HttpServer    override fun start(startFuture: Future&lt;Void&gt;){        //初始化一个TCP客户端，后面要用        netClient = vertx.createNetClient()        //初始化HTTP服务端        httpServer = vertx.createHttpServer()        //设置websocket处理器,用于处理所有与websocket相关的功能        httpServer.websocketHandler(this::socketHandler)        httpServer.listen(port,it.completer()){            logger.info(&quot;Proxy server listen at $port&quot;)            startFuture.complete()        }    }    private fun socketHandler(sock: ServerWebSocket){        sock.binaryMessageHandler { buffer -&gt;            GlobalScope.launch(vertx.dispatcher()) {                when (buffer.getIntLE(0)) {                    //处理连接请求                    Flag.CONNECT.ordinal -&gt; clientConnectHandler(sock, ClientConnect(buffer))                    //处理数据请求                    Flag.RAW.ordinal -&gt; clientRawHandler(sock, RawData(buffer))                }            }        }        //接受连接，可以在这之前做一些鉴权的工作        sock.accept()    }}</code></pre><p>服务端的整体结构就如Demo所示，在服务端接受了客户端的websocket握手之后，就会处理客户端发送的两种请求。下面是两种请求处理的实现</p><pre><code class="Kotlin">//处理连接请求private suspend fun clientConnectHandler(sock: ServerWebSocket, data:ClientConnect){    try {        //TCP Client尝试连接到目标服务器        val net = netClient.connectAwait(data.port, data.host)        //连接成功则设置handler        net.handler { buffer-&gt;        //把目标服务器返回的数据加密发送给客户端            sock.writeBinaryMessage(RawData.create(data.uuid,buffer).toBuffer())        }.closeHandler {            localMap.remove(data.uuid)        }        localMap[data.uuid] = net    }catch (e:Throwable){      logger.warn(e.message)      //连接失败则告诉客户端连接失败      sock.writeBinaryMessage(Exception.create(data.uuid,e.localizedMessage).toBuffer())      return    }    //告诉客户端连接成功    sock.writeBinaryMessage(ConnectSuccess.create(data.uuid).toBuffer())}//处理数据请求private fun clientRawHandler(sock: ServerWebSocket, data: RawData){    val net = localMap[data.uuid]    //把客户端的数据解密发送目标服务器    net?.write(data.data)?:let{        sock.writeBinaryMessage(Exception.create(data.uuid,&quot;Remote socket has closed&quot;).toBuffer())    }}</code></pre><p>其中uuid是为了保证数据在传输过程中能够找到请求发起者，不然客户端收到了返回的数据，会出现不知道是谁发起的问题。当然这个问题也可以用其他方式实现，理论上说，封装的再完善一点的话，是能够只靠闭包解决。<br>以下是RawData类，展示数据加密过程,加密方式是<code>AES/CBC/PKCS5Padding</code>，javax库中提供的加密方式</p><pre><code class="Kotlin">class RawData(private val buffer:Buffer) {    private val decryptedBuffer = Buffer.buffer(Aes.decrypt(buffer.getBytes(Int.SIZE_BYTES,buffer.length())))    private val uuidLength = decryptedBuffer.getIntLE(0)    val uuid = decryptedBuffer.getString(Int.SIZE_BYTES,Int.SIZE_BYTES+uuidLength)    val data = decryptedBuffer.getBuffer(Int.SIZE_BYTES+uuidLength,decryptedBuffer.length())    fun toBuffer() = buffer    companion object {        fun create(uuid:String,data:Buffer):RawData {        val encryptedBuffer = Aes.encrypt(Buffer.buffer()            .appendIntLE(uuid.length)            .appendString(uuid)            .appendBuffer(data).bytes)        return RawData(Buffer.buffer()            .appendIntLE(Flag.RAW.ordinal)            .appendBytes(encryptedBuffer))        }    }}</code></pre><p>到此，服务端的功能就实现了。接下来就是如何实现客户端</p><h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><p>客户端与浏览器交互的部分，我们选择Socks5协议，这个Vert.x库不带支持，所以需要自己实现以下。实现代码可以看Wsocks的ClientSocks5类，这里只展示客户端与服务端的交互。</p><pre><code class="Kotlin">//核心部分httpClient.websocket(remotePort,remoteIp,&quot;/proxy&quot;){ webSocket -&gt;      webSocket.binaryMessageHandler {buffer-&gt;        if (buffer.length() &lt; 4) {          return@binaryMessageHandler        }        when (buffer.getIntLE(0)) {          //连接成功          Flag.CONNECT_SUCCESS.ordinal -&gt; wsConnectedHandler(ConnectSuccess(buffer).uuid)          //出现异常          Flag.EXCEPTION.ordinal -&gt; wsExceptionHandler(Exception(buffer))          //目标服务器返回数据          Flag.RAW.ordinal -&gt; wsReceivedRawHandler(RawData(buffer))          else -&gt; logger.warn(buffer.getIntLE(0))        }      }    }</code></pre><pre><code class="Kotlin">//处理器部分private fun wsConnectedHandler(uuid:String){    val netSocket = connectMap[uuid]?:return    netSocket.handler {      //将浏览器的数据，加密发送到服务端      ws.writeBinaryMessage(offset,RawData.create(uuid,it).toBuffer())    }    //告诉浏览器连接成功    val buffer = Buffer.buffer()      .appendByte(0x05.toByte())      .appendByte(0x00.toByte())      .appendByte(0x00.toByte())      .appendByte(0x01.toByte())      .appendBytes(ByteArray(6){0x0})    netSocket.write(buffer)}private fun wsReceivedRawHandler(data: RawData){    val netSocket = connectMap[data.uuid]?:return    bufferSizeHistory+=data.data.length()    //把解密后的数据发送给浏览器    netSocket.write(data.data)}private fun wsExceptionHandler(e:Exception){    //出现异常，断开浏览器本次连接    connectMap.remove(e.uuid)?.close()}</code></pre><p>至此，浏览器和客户端，客户端和服务端，服务端和目标服务器之间的数据交互就完成了。</p><h2 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h2><p>由于我只是个普通写后台的，并不是专业的密码学研究者，所以对于加密这块内容，也不敢做过多的分析。但是结合GFW所处的实际情况，我觉得自己还是可以稍微评论一下的。实际上Github上也还有一些类Shadowsocks的产品，比如说<code>Lightsocks</code>，star数也挺高。它们有些产品采用了自己开发的加密算法，而不是<code>Aes</code>，<code>Rc4</code>，之类的主流加密。按照作者的意思是，采用自己开发的加密能够更加有效的方式GFW解密。<br>这么说当然也是有一定道理的，但是实际上这些自研的算法往往比较脆弱，更容易遭到像词频分析之类的方法解密。但是其实我们还要考虑一个问题，GFW只是一个部署在主干网络上的计算机集群，它不是神，它的模型、运算量都是有限的， 每秒都有大量的流量经过它，要通过分析流量<em>解密</em>数据很明显是不可能的事情，就算我们总说Aes128过时了，Aes128有漏洞，但是针对Aes128的攻击依然条件苛刻。<br>在这里还可以举个例子，SSL我们都认为它是安全的，但是针对SSL或者说HTTPS的<em>中间人</em>攻击是存在的，只是这种攻击实现的原理绝对不是分析加密后的数据，而是通过分析<strong>握手环节</strong>的数据拿到秘钥来解密后续的数据。同样的，GFW也是这么做的，而对于这种情况，只要秘钥不出现在流量中，GFW就很难有操作的空间了。<br>还可以再举另一个例子，杀毒软件判断一个程序是否是病毒、木马，靠的是<strong>特征码</strong>和<strong>行为分析</strong>，<strong>特征码</strong>就是病毒为了执行某一系列操作而必定存在的代码，而<strong>行为分析</strong>则是把病毒放在沙箱环境内，观察病毒做了哪些操作。GFW也是如此，在流量中查找特征码比解密流量要容易的多，像Shadowsocks这样的程序产生的流量特征是很明显的，除此之外，GFW还拥有主动探测的能力，在发现特征后，它会尝试构造特殊的报文发送给目标，并根据目标的行为判断是否为Shadowsocks服务端。这种嗅探的成本也是非常低的。 </p><h2 id="完善"><a href="#完善" class="headerlink" title="完善"></a>完善</h2><p>就如我在前面写的，使用Websocket这样的协议能够把我们的流量伪装成正常的网站流量。当然这并不完善，因为这样的程序一旦多起来，GFW也一定会开发出针对Websocket的特征分析。这个时候就需要一种更加灵活的方式，比如在数据头部填充，在报文的某几个位置插入字节。这些都可以破坏报文的特征，就像我们给病毒修改入口点、加壳、加花，来起到免杀的效果一样。<br>针对GFW的主动嗅探，则可以考虑动态白名单之类的机制，想要发送请求，就要到另一台服务器上登录，登录过程可以经过国内一台服务器做跳板，这样对于GFW来说，整个过程就是两组不相干的流量。如果要将这样的流量放在一起建立模型的话，也许要到2050年吧。</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>国内普遍言论还是把GFW神化了，这东西确实很强，也不知道是哪些研究所在负责维护，但是毕竟算法再强，模型再完美也要受硬件所限。这方面，Google没有解决的问题，中国政府也尚且没有这样的实力。很多时候，解决问题还是不要硬刚，换个角度想一下，可能效果更好。</p>]]></content>
      
      
        <tags>
            
            <tag> Kotlin </tag>
            
            <tag> Vert.x </tag>
            
            <tag> VPN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Nginx配置fastcgi-perl</title>
      <link href="/2018/09/08/Nginx%E9%85%8D%E7%BD%AEfastcgi-perl/"/>
      <url>/2018/09/08/Nginx%E9%85%8D%E7%BD%AEfastcgi-perl/</url>
      <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h2><p>廉价VPS的小内存实在是供不起JVM，所以只好找别的出路了。php呢不是很喜欢，python又不是很想用，于是选了个硬核一点的Perl作为后端语言。反正前后分离，没了渲染压力后端想怎么玩怎么玩。</p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a><strong>正文</strong></h2><pre><code class="Shell">apt-get install nginx libfcgi-perl wget</code></pre><p>改nginx配置</p><pre><code>server {  listen   80;  root   /var/www/example.com;  location / {      index  index.html index.htm index.pl;  }    location ~ \.pl|cgi$ {      try_files $uri =404;      gzip off;      fastcgi_pass  127.0.0.1:8999;      fastcgi_index index.pl;      fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;      include fastcgi_params;      }}</code></pre><p>创建目录,给权限</p><pre><code class="Shell">mkdir /var/www/example.comchown -R www-data:www-data /var/www/example.com</code></pre><p>下载配置FastCGI</p><pre><code class="Shell">wget http://nginxlibrary.com/downloads/perl-fcgi/fastcgi-wrapper -O /usr/bin/fastcgi-wrapper.plwget http://nginxlibrary.com/downloads/perl-fcgi/perl-fcgi -O /etc/init.d/perl-fcgichmod +x /usr/bin/fastcgi-wrapper.plchmod +x /etc/init.d/perl-fcgiupdate-rc.d perl-fcgi defaults/usr/lib/insserv/insserv perl-fcgi</code></pre><p>启动!</p><pre><code class="Shell">service nginx startservice perl-fcgi start</code></pre><h2 id="坑"><a href="#坑" class="headerlink" title="坑"></a><strong>坑</strong></h2><p>顺利的话，就启动了。不顺利的话，启动perl-fastcgi的时候会失败，报错说<code>this account is currently not available</code>。Google了一圈好像没人在配置cgi的时候遇到这样的问题，比较多的是有些脑洞大开的人想从ssh登录到www-data这个用户上。<br>顺便说一下www-data这个用户，如果看Nginx的进程的话</p><pre><code class="Shell">ps -ef | grep nginx</code></pre><p>会看到nginx的几个worker-process所属的用户都是www-data，这个就是专门给web应用提供的用户。<br>看了一下这些登录不了的解决方案，发现cgi的问题应该也可以用同样的方法解决。</p><p>在<code>/etc/passwd</code>里，我们可以找到www-data的那行，然后就会发现它的结尾是<code>/usr/sbin/nologin</code>，我们要改成<code>/bin/bash</code>。这样这个用户就有运行perl脚本的能力了。重新启动一下服务，就OK了。</p>]]></content>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
            <tag> perl </tag>
            
            <tag> 运维 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>See what&#39;s comming in Kotlin 1.3-M1 译文</title>
      <link href="/2018/08/11/See-what-s-comming-in-Kotlin-1-3-M1/"/>
      <url>/2018/08/11/See-what-s-comming-in-Kotlin-1-3-M1/</url>
      <content type="html"><![CDATA[<blockquote><p>原文在:<br><a href="https://blog.jetbrains.com/kotlin/2018/07/see-whats-coming-in-kotlin-1-3-m1/" target="_blank" rel="noopener">https://blog.jetbrains.com/kotlin/2018/07/see-whats-coming-in-kotlin-1-3-m1/</a>   </p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>今天，在一长串的关于Kotlin 1.2.x的更新之后，是时候看看Kotlin 1.3会带来什么。我们很高兴的宣布Kotlin 1.3的尝鲜体验版Kotlin 1.3-M1正式发布。<br>Kotlin 1.3相比之前版本有许多的进步，其中包括 <em>完全体的协程</em>，<em>实验版的无符号类型</em>(Java至今没有的东西),<em>inline class</em> 以及其他更多特性。<br>这里要感谢为我们的新版本贡献代码的社区群众:Raluca Sauciuc, Toshiaki Kameyama, Leonardo Lopes, Jake Wharton, Jeff Wright, Lucas Smaira, Mon_chi, Nico Mandery, Oskar Drozda.  </p><blockquote><p>完整的ChangeLog<br><a href="https://github.com/JetBrains/kotlin/blob/1.3-M1/ChangeLog.md" target="_blank" rel="noopener">https://github.com/JetBrains/kotlin/blob/1.3-M1/ChangeLog.md</a></p></blockquote><h1 id="稳定版的协程-1-3之前一直是实验版"><a href="#稳定版的协程-1-3之前一直是实验版" class="headerlink" title="稳定版的协程(1.3之前一直是实验版)"></a>稳定版的协程(1.3之前一直是实验版)</h1><p>终于，在1.3中协程不再是实验性的。无论是语法糖还是标准库都将趋于稳定并且保持向后兼容。自从1.1版本加入协程之后，协程这一特性一直保持着显著的提高。</p><blockquote><p>几个重要的特性<br>KT-16908 Support callable references to suspending functions<br>KT-18559 Serializability of all coroutine-related classes</p></blockquote><p>现在，我们简化了协程的核心API，并且去掉了<code>experimental</code>包。同时，我们还在协程的跨平台性中做了许多工作，包括对基于Kotlin/Native（Kotlin的LLVM版本)的IOS支持</p><h3 id="转战新协程"><a href="#转战新协程" class="headerlink" title="转战新协程"></a>转战新协程</h3><p>就像我们之前说的一样，所有与协程有关的函数都都已经丢掉了<code>experimental</code>的包名。同时，<code>buildSequence</code>和<code>buildIterator</code>函数也放到了他们在<code>kotlin.sequences</code>包中常驻的地方。<br>在语言的层面上，我们仍然使用<code>suspend</code>关键字来支持协程并且所有的规则几乎与实验版中的规则一致。<br>我们简化了稳定版中的<code>Continuation&lt;T&gt;</code>接口。现在它只保留了 <code>resumeWith(result: SuccessOrFailure&lt;T&gt;)</code>这一个成员函数。原先的<code>resume(value: T)</code>和<code>resumeWithException(exception: Throwable)</code>现在以扩展的形式出现。这个改动只影响了那些少数自己定义协程构造器，那些将回调函数包装成挂起函数(suspending functions)的代码大多数不会发生改变。比如说，为类<code>CompletableFuture&lt;T&gt;</code>定义挂起函数<code>await()</code>还是会像之前一样。</p><pre><code class="Kotlin">suspend fun &lt;T&gt; CompletableFuture&lt;T&gt;.await(): T = suspendCoroutine { cont -&gt;    whenComplete { value, exception -&gt;        when {            exception != null -&gt; cont.resumeWithException(exception)            else -&gt; cont.resume(value)        }    }}</code></pre><p>稳定版的协程采用了不同的二进制接口，它们并不能与实验版的协程二进制兼容。为了确保代码能够平稳的转移，我们将在1.3中增加一个兼容层，并且实验版中的类都将保留在标准库中。在Kotlin/JVM中使用Kotlin 1.1-1.2的已经编译好的代码都能在Kotlin 1.3中运行。<br>但是Kotlin 1.3中不提供任何调用1.2(原文中写了1.3，应该是写错了)版本中编译好的实验性协程的支持。如果想要在1.3稳定版协程中使用旧版本协程的库，你需要在1.3版本下重新编译它们。这只是一个暂时的问题，我们会尽快处理。(JetBrains团队的尽快，往往是真的很快)<br>我们还将提供<code>kotlinx.coroutines</code>库的<code>x.x.x-eap13</code>版本。<br>IDE将提示你转移到新的协程上去。我们会在1.3正式版发布前进一步扩大协程的使用范围。</p><h1 id="一些新特性"><a href="#一些新特性" class="headerlink" title="一些新特性"></a>一些新特性</h1><p>更重要的特性会出现在实验性部分，这里只提一些为大家带来便利的小特性</p><h3 id="捕获when中的参数"><a href="#捕获when中的参数" class="headerlink" title="捕获when中的参数"></a>捕获when中的参数</h3><p>这段懒得翻译了，就看一下代码吧。已经非常明了了</p><pre><code class="Kotlin">fun Request.getBody() =    when (val response = executeRequest()) {        is Success -&gt; response.body        is HttpError -&gt; throw HttpException(response.status)    }</code></pre><h3 id="伴生接口中的-JvmStatic和-JvmField"><a href="#伴生接口中的-JvmStatic和-JvmField" class="headerlink" title="伴生接口中的@JvmStatic和@JvmField"></a>伴生接口中的@JvmStatic和@JvmField</h3><pre><code class="Kotlin">interface Service {    companion object {        @JvmField        val ID = 0xF0EF        @JvmStatic        fun create(): Service = ...    }}</code></pre><p>Kotlin中的接口现在可以把静态成员暴露给Java(捞你Java一手)。</p><h3 id="可嵌套的注解声明"><a href="#可嵌套的注解声明" class="headerlink" title="可嵌套的注解声明"></a>可嵌套的注解声明</h3><p>在Kotlin 1.3之前，注解类不能拥有类体(bodies)。1.3版本放宽了这一限制，现在我们允许注解类拥有嵌套类，接口和伴生对象</p><pre><code class="Kotlin">annotation class Outer(val param: Inner) {    annotation class Inner(val value: String)}annotation class Annotation {    companion object {        @JvmField        val timestamp = System.currentTimeMillis()    }}</code></pre><h3 id="函数类型可以有更多参数"><a href="#函数类型可以有更多参数" class="headerlink" title="函数类型可以有更多参数"></a>函数类型可以有更多参数</h3><p>现在一个函数类型，可以拥有超过22个参数了！(Kotlin的一个梗，程序员的暴力美学)。我们现在将上限提高到了JVM的极限——255。如果你想知道我们是怎么做到在不定义额外233个类的情况下实现这个功能的话，请看这里</p><blockquote><p><a href="https://github.com/Kotlin/KEEP/blob/master/proposals/functional-types-with-big-arity-on-jvm.md" target="_blank" rel="noopener">https://github.com/Kotlin/KEEP/blob/master/proposals/functional-types-with-big-arity-on-jvm.md</a></p></blockquote><h1 id="实验性特性"><a href="#实验性特性" class="headerlink" title="实验性特性"></a>实验性特性</h1><p>就像协程已经证明了的一样，通过把EAP的重要特性设为实验性能帮助我们从社区中收集到可贵的反馈。我们将继续使用这个技术，让Kotlin的所有特性都经过实战的检验。Kotlin 1.3将带来三个激动人心的实验性特性。你需要明确选择使用这些特性，不然编译器会提示警告或者错误。</p><h3 id="内联类"><a href="#内联类" class="headerlink" title="内联类"></a>内联类</h3><p>内联类能让你在不用真正创建一个类的情况下包装某个类型。</p><pre><code class="Kotlin">inline class Name(internal val value: String)</code></pre><p>当使用这样一个类的时候，编译器会内联它的内容，并且所有操作会直接作用在被包装的类本身。于是，就像下面这样</p><pre><code class="Kotlin">val name: Name = Name(&quot;Mike&quot;)fun capitalize(name: Name): Name = Name(name.value.capitalize())</code></pre><p>编译结果会与下面的代码一样</p><pre><code class="Kotlin">val name: String = &quot;Mike&quot;fun capitalize(name: String): String = name.capitalize()</code></pre><p>内联类与类型别名有些相似，但它们不是赋值兼容的。所以你不能把<code>String</code>赋值给<code>Name</code>,反之亦然。<br>由于内联类实际并不存在，所以不能对它们使用<code>===</code>操作符。<br>还有其他内联类产生包装器的地方，就像<code>Int</code>的装箱一样</p><pre><code class="Kotlin">val key: Any = Name(&quot;Mike&quot;) // boxing to actual Name wrapperval pair = Name(&quot;Mike&quot;) to 27 // Pair is a generic type, so Name is boxed here too</code></pre><p>这个特性可以通过添加编译选项<code>-XXLanguage:+InlineClasses</code>来开启</p><h3 id="无符号数字类型"><a href="#无符号数字类型" class="headerlink" title="无符号数字类型"></a>无符号数字类型</h3><p>内联类最明显的应用就是无符号类型。现在标准库已经加入了<code>UInt</code>，<code>ULong</code>，<code>UByte</code>和<code>UShort</code>。通过内联类，这些类型定义了自己的运算符，可以将存储的数值转化为无符号类型。</p><pre><code class="Kotlin">val operand1 = 42val operand2 = 1000 * 100_000val signed: Int = operand1 * operand2val unsigned: UInt = operand1.toUInt() * operand2.toUInt()</code></pre><p>除了新的类型，我们还添加了一些新的语言特性来让它们变得特殊</p><ul><li><p>允许在变长参数中使用无符号类型，这与其他内联类不用</p><pre><code class="Kotlin">fun maxOf(vararg values: UInt): UInt { ... }</code></pre></li><li><p>无符号类型的关键字</p><pre><code class="Kotlin">val uintMask = 0xFFFF_FFFFuval ulongUpperPartMask = 0xFFFF_FFFF_0000_0000uL</code></pre></li><li><p>无符号常量</p><pre><code class="Kotlin">const val MAX_SIZE = 32768u//Koltin 1.3-M1暂不支持无符号常量的复杂表达式const val MAX_SIZE_BITS = MAX_SIZE * 8u // Error in 1.3-M1</code></pre></li></ul><p>为了使用无符号类型，你需要选择启动它们</p><ul><li>either annotate the code element that uses unsigned types with the @UseExperimental(ExperimentalUnsignedTypes::class) annotation</li><li>or specify the -Xuse-experimental=kotlin.ExperimentalUnsignedTypes compiler option.</li></ul><h1 id="新的标准库API"><a href="#新的标准库API" class="headerlink" title="新的标准库API"></a>新的标准库API</h1><p>现在让我们看看1.3中的新API</p><h3 id="SuccessOrFailure"><a href="#SuccessOrFailure" class="headerlink" title="SuccessOrFailure"></a>SuccessOrFailure</h3><p>内联类<code>SuccessOrFailure</code>是一个有效的判别函数执行成功或失败<code>Success T | Failure Throwable</code>的集合。它被用来捕获函数的执行结果无论成功或失败，以便于我们在之后的代码中处理它们。</p><pre><code class="Kotlin">val files = listOf(File(&quot;a.txt&quot;), File(&quot;b.txt&quot;), File(&quot;42.txt&quot;))val contents: List&lt;SuccessOrFailure&lt;String&gt;&gt; = files.map { runCatching { readFileData(it) } }println(&quot;map successful items:&quot;)val upperCaseContents: List&lt;SuccessOrFailure&lt;String&gt;&gt; =    contents.map { r -&gt; r.map { it.toUpperCase() } }upperCaseContents.printResults()println()println(&quot;map successful items catching error from transform operation:&quot;)val intContents: List&lt;SuccessOrFailure&lt;Int&gt;&gt; =    contents.map { r -&gt; r.mapCatching { it.toInt() } }intContents.printResults()</code></pre><p>引入这个类最主要的原因是我们想要在新的协程接口中使用<code>resumeWith(result: SuccessOrFailure&lt;T&gt;)</code>而不是<code>resume(T)</code>和<code>resumeWithException(Throwable)</code></p><h3 id="多平台随机数生成器"><a href="#多平台随机数生成器" class="headerlink" title="多平台随机数生成器"></a>多平台随机数生成器</h3><p>没啥好说的，原本Kotlin/JVM的东西现在支持Kotlin的所有平台了</p><h3 id="Boolean类型的伴生对象"><a href="#Boolean类型的伴生对象" class="headerlink" title="Boolean类型的伴生对象"></a>Boolean类型的伴生对象</h3><p>为Boolean加了个内容为空的伴生对象。今后可能有用，像各种类型比较，转换之类的地方。</p><h3 id="基本类型伴生对象的常亮"><a href="#基本类型伴生对象的常亮" class="headerlink" title="基本类型伴生对象的常亮"></a>基本类型伴生对象的常亮</h3><ul><li><p>为Byte, Short, Int, Long, Char几个类型加入了SIZE_BITS和SIZE_BYTES</p></li><li><p>为Char增加了MAX_VALUE(‘\u0000’)和MIN_VALUE(‘\uFFFF’)</p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>JetBrains的效率是真的挺高。2018年6月发布Kotlin 1.2.50，转眼1个月之后又发布了1.3-M1。1.3版本比较重要的就是协程不再带有实验性标志。同时最有趣的就是内联类了。</p>]]></content>
      
      
        <tags>
            
            <tag> Kotlin </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SQL简单调优(1)</title>
      <link href="/2018/07/30/SQL%E7%AE%80%E5%8D%95%E8%B0%83%E4%BC%98-1/"/>
      <url>/2018/07/30/SQL%E7%AE%80%E5%8D%95%E8%B0%83%E4%BC%98-1/</url>
      <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1.前言"></a><strong>1.前言</strong></h2><p>先说一下背景，这几天在公司里接触了几个比较大的表，数据量在10万条到400万条之间，公司用的数据库是Oracle。所以如果这篇博客中描述的情况与你所遇到的情况不符的话，很有可能是数据量和数据库的问题。</p><h2 id="2-联表与子查"><a href="#2-联表与子查" class="headerlink" title="2.联表与子查"></a><strong>2.联表与子查</strong></h2><p>首先说一下业务的需求:<em>输入一个时间段，找到这个时间段里流失的客户。客户流失的逻辑:如果这个客户从最后一次下单到下单后的45天内没有下单则认为这个客户流失了</em>  数据库里有一张表(sap_vbak)维护着所有的订单，其中有订单号（vbeln),对应客户(kunnr),创建日期(erdat)。<br>一开始拿到这个需求的时候想的很简单，大致分为两步:1.取出时间段内所有的订单 2.得到所有订单时间后计算出45天的时间段再取出这个时间段内所有的订单，如果不存在则认为客户流失，于是SQL语句就变成这样</p><pre><code class="SQL">SELECT vbeln,kunnr,erdat FROM (  SELECT k.vbeln,k.kunnr,k.erdat,(SELECT temp.vbeln FROM sap_vbak temp WHERE temp.erdat &lt; k.erdat and temp.erdat &gt;= k.erdat - 45 and temp.kunnr = k.kunnr and rownum = 1) tmp FROM sap_vbak k  WHERE k.erdat &gt;= to_date(&#39;2018-01-01&#39;,&#39;yyyy-MM-dd&#39;) and k.erdat &lt;= to_date(&#39;2018-01-05&#39;,&#39;yyyy-MM-dd&#39;) group by k.vbeln,k.kunnr,k.erdat) WHERE tmp is null;</code></pre><p>三层的查询，逻辑非常清楚。但是这里问题就来了，由于数据量太大了，这个SQL要想跑出结果得花15分钟。其中对于速度影响最大的就是这里的 <em>标量子查询</em> 了。<br>于是在公司前辈的指点下，把子查询改成了联表</p><pre><code class="SQL">SELECT k.vbeln,k.kunnr,k.erdat FROM sap_vbak kLEFT JOIN sap_vbak temp ON temp.erdat &lt; k.erdat and temp.erdat &gt;= k.erdat - 45 and temp.kunnr = k.kunnrWHERE k.erdat &gt;= to_date(&#39;2018-01-01&#39;,&#39;yyyy-MM-dd&#39;) and k.erdat &lt;= to_date(&#39;2018-01-15&#39;,&#39;yyyy-MM-dd&#39;) and temp.vbeln is null;</code></pre><p>这段SQL的效果非常好，跑出结果大概只要40秒。思路其实也很简单，把原先子查询的部分换成LEFT JOIN，得到一张临时表这张表记录着每个订单与它45天内同一个客户的所有订单，然后只要在这张表中选出tmp字段(即同一客户的订单)是null的结果即可。</p><p>后来发现另一种不通过联表的方法也可以提高查询效率</p><pre><code class="SQL">SELECT k.vbeln,k.kunnr,k.erdat FROM sap_vbak kWHERE k.erdat &gt;= to_date(&#39;2018-01-01&#39;,&#39;yyyy-MM-dd&#39;) and k.erdat &lt;= to_date(&#39;2018-01-05&#39;,&#39;yyyy-MM-dd&#39;)and not exists (SELECT temp.vbeln FROM sap_vbak temp WHERE temp.erdat &lt; k.erdat and temp.erdat &gt;= k.erdat - 45 and temp.kunnr = k.kunnr);</code></pre><p>把原先的标量子查询改成了WHERE后面的 <em>not exists</em> ，查询时间也从原本的15分钟，变到了5分钟以内。</p>]]></content>
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Ubuntu求生指南(1)</title>
      <link href="/2018/07/16/Ubuntu%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-1/"/>
      <url>/2018/07/16/Ubuntu%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97-1/</url>
      <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1.前言"></a><strong>1.前言</strong></h2><p>先抱怨两句，Linux对于各种A卡的支持实在是太烂了。Radeon的驱动下，A卡的跑分还不到Intel的一半。换用AMD自家的amdgpu-pro直接就进不了桌面系统了。搞了好几天还是搞不定，最后还是决定算了，毕竟核显跑Minecraft还是有40-60帧。不用独显说不定还能省点电。<br>如果你不幸也是A卡用户，这篇文章了应该能给你点帮助。如果你N卡用户，这篇文章也还是有点用的，说不定哪天就能救人一命。<br>如果你想看看自己的显卡/各种设备的情况的话，用<code>lspci</code>这个命令,参数<code>-k</code>的使用率比较高。</p><h2 id="2-AMDGPU-PRO"><a href="#2-AMDGPU-PRO" class="headerlink" title="2.AMDGPU-PRO"></a><strong>2.AMDGPU-PRO</strong></h2><blockquote><p>Ubuntu 18.04对应下载地址<br><a href="https://support.amd.com/en-us/kb-articles/Pages/Radeon-Software-for-Linux-18.20-Early-Preview-Release-Notes.aspx" target="_blank" rel="noopener">https://support.amd.com/en-us/kb-articles/Pages/Radeon-Software-for-Linux-18.20-Early-Preview-Release-Notes.aspx</a></p></blockquote><blockquote><p>Ubuntu 16.04对应下载地址<br><a href="https://support.amd.com/en-us/kb-articles/Pages/AMDGPU-PRO-Driver-for-Linux-Release-Notes.aspx" target="_blank" rel="noopener">https://support.amd.com/en-us/kb-articles/Pages/AMDGPU-PRO-Driver-for-Linux-Release-Notes.aspx</a></p></blockquote><p>相信看看链接大家也就懂了。18.04还是EPR，能不能用就看造化了。16.04应该能用，但是我不确定，因为我是ubuntu gnome16.04。<code>稍微科普一下，ubuntu17.10前的桌面系统是Unity，然后因为大家喜好有差，就出现了Ubuntu Gnome和KUbuntu(Ubuntu Kde)这两个发行版</code>然后amdgpu-pro在我的电脑上似乎不太行，如果你是官方的Ubuntu发行版，说不定可以试试。<br>安装完之后不要忘了修改grub</p><blockquote><pre><code>   Edit /etc/default/grub as root and modify GRUB_CMDLINE_LINUX_DEFAULT in order to add &quot;amdgpu.vm_fragment_size=9&quot; (without the quotes). The line may look something like this after the change:    GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash amdgpu.vm_fragment_size=9&quot;    Update grub and reboot as root:    update-grub;reboot</code></pre></blockquote><p>官方丧心病狂的把这段话写在网页的后半部分，可能很多人都没有注意。</p><p>接下来就是非常关键的部分了。如果你安装完之后成功的进入了桌面系统，你可能会在gnome的 <em>设置-&gt;详细信息-&gt;图形</em> 里看到LLVM的字样(顺便说一句，看到LLVM的时候我就总觉得这玩意不太靠谱)，当然根据显卡型号不同，你可能会看到不一样的结果。只要你没看到Intel之类的东西，你多半是成功了。  </p><p>对于成功者来说，这部分就到此结束了。但是如果你安装了amdgpu-pro之后，出现开机只能进bash或者登录界面循环的情况，你可能就不得不浪费一些时间了。<strong>Ubuntu Ask</strong> 论坛上有许多关于这种问题的帖子，里面说不定有些解决方案。而这里，我只给一种最简单的方案。<br>在amdgpu-pro安装之后，系统会多一个<code>amdgpu-pro-uninstall</code>的命令。我们要在boot的时候选择<code>recovery mode</code>。进入recovery mode之后，可以先选择一下clean，这样他会自动挂载分区。clean结束之后，就进入root然后运行<code>amdgpu-pro-uninstall</code>就可以了，同时不要忘了把grub改回来。</p><h2 id="2-某不靠谱PPA"><a href="#2-某不靠谱PPA" class="headerlink" title="2.某不靠谱PPA"></a><strong>2.某不靠谱PPA</strong></h2><p>可能在尝试amdgpu-pro之前，你还试过很多操作。毕竟那些年代久远的文章总是会介绍一些奇奇怪怪的方法。。。然后，我就遭众了。<br>这里的方法不只是对安装驱动的时候遇到的问题有效，所有因为安装了某ppa的应用而导致问题的情况都可以用这个方法解决。<br><em>PPA回滚</em></p><blockquote><p>sudo apt-get install ppa-purge<br>sudo ppa-purge ppa:你要删除的ppa</p></blockquote><p>跟上面一样，进了<code>recovery mode</code>之后就可以运行这两行命令，把刚刚安装的程序删掉就可以了。</p><h2 id="3-我并不知道我刚刚装了什么东西"><a href="#3-我并不知道我刚刚装了什么东西" class="headerlink" title="3.我并不知道我刚刚装了什么东西"></a><strong>3.我并不知道我刚刚装了什么东西</strong></h2><p>这是最难受的。但是只要我们安装的东西全都是通过apt安装的，那么这个问题就还可以解决。首先apt的安装都是有日志的，我的位置在<code>/var/log/apt/history.log</code>,我们只要找到最近一段时间里安装的包并且把他们删掉就行了。<br>我们可以在<code>recovery mode</code>里用vim打开这个log，找到文件尾处的安装信息。有时候会出现一次安装的包太多的情况，这个时候就需要用一些命令处理一下。</p><blockquote><p>这里给一个范例<br><code>grep -A 3 &#39;Start-Date: 2018-07-16  22:56:10&#39; /var/log/apt/history.log |sudo tail -1 &gt; tmp.log</code><br>再用Vim删除一些不用的信息<br><code>tr &#39; &#39; &#39;\n&#39; &lt;tmp.log | sed &#39;/,$/d&#39; &gt; tmp0.log</code><br>再删除最后一行</p></blockquote><p>最终就可以得到一个完整的安装列表。<br>写一个脚本</p><pre><code class="Shell"># Run as root# Store packages name in $pp=&quot;$(&lt;/tmp/final.packages.txt)&quot;# Nuke itapt-get --purge remove $p#clears out the local repository of retrieved package filesapt-get clean# Just in case ...apt-get autoremove</code></pre><p>运行一下，大功告成。</p>]]></content>
      
      
        <tags>
            
            <tag> 杂谈 </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>为什么Kotlin排在第49位</title>
      <link href="/2018/07/05/%E4%B8%BA%E4%BB%80%E4%B9%88Kotlin%E6%8E%92%E5%9C%A8%E7%AC%AC49%E4%BD%8D/"/>
      <url>/2018/07/05/%E4%B8%BA%E4%BB%80%E4%B9%88Kotlin%E6%8E%92%E5%9C%A8%E7%AC%AC49%E4%BD%8D/</url>
      <content type="html"><![CDATA[<h2 id="FUCK"><a href="#FUCK" class="headerlink" title="FUCK"></a>FUCK</h2>]]></content>
      
      
        <tags>
            
            <tag> Kotlin </tag>
            
            <tag> 杂谈 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Vert.x后端漫游指南(3)</title>
      <link href="/2018/07/03/Vert-x%E5%90%8E%E7%AB%AF%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8D%97-3/"/>
      <url>/2018/07/03/Vert-x%E5%90%8E%E7%AB%AF%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8D%97-3/</url>
      <content type="html"><![CDATA[<h2 id="1-异步之痛"><a href="#1-异步之痛" class="headerlink" title="1.异步之痛"></a><strong>1.异步之痛</strong></h2><p>上一篇中，我们为登录部分加入了读取数据库的操作。如果你熟悉JDBC的话，应该很快就发现了Vert.x中异步的数据库操作与JDBC中同步操作的不同。我们不再像以前一样等待着数据库的返回值，相反的，我们将自己的后续操作包装在一个lambda中，作为参数传递给<code>query</code>方法。在查询完成之后，<em>SqlClient</em> 会来调用我们传入的lambda并将查询结果作为参数传递给我们。<br>这样的过程就是一个非常经典的异步过程，似乎非常的简单并且也没有什么不合理的地方。但是仔细想一想我们实际的需求，就会发现这个过程好像并没有这么美好。很多情况下，我们要在一个一个请求处理中多次操作数据库，现在假设我们在做一个社交网站。用户登录之后我们要返回用户的基本信息，用户的好友信息，还有用户曾经发表的图片、文章。很明显，我们要做三次查询操作，于是我们的代码就变成了这样</p><pre><code class="Kotlin">sqlClient.querySingleWithParams(&quot;SELECT id,birthday,full_name,nick_name,email FROM user WHERE uname=? and pwd=?&quot;,JsonArray(uname,pwd)){  if(it.failed()){    //DO some  }else{    val uid = it.result().getInteger(0)    sqlClient.queryWithParams(&quot;SELECT * FROM friends WHERE uid=?&quot;,JsonArray(uid)){      if(it.failed()){        //Do some      }else{        sqlClient.queryWithParams(&quot;SELECT * FROM posts WHERE uid=?&quot;,JsonArray(uid)){          if(it.failed()){            //Do some          }else{            context.response().end(/*All infomations*/)          }        }      }    }  }}</code></pre><p>很多的业务逻辑要求我们必须保证代码的执行顺序，这对于同步的代码来说非常的简单，但是对于异步的构架，我们不得不做一点改变，否则我们的代码会像金字塔一样越叠越高。<br>为了解决这种问题，我们有很多种选择。如果你不幸选择使用Java的话，RxJava应该会成为你最好的选择，但是如果你选择Kotlin，那么你就有了一个非常简单的解决方案。</p><h2 id="2-协程"><a href="#2-协程" class="headerlink" title="2.协程"></a><strong>2.协程</strong></h2><h4 id="1）协程能干嘛"><a href="#1）协程能干嘛" class="headerlink" title="1）协程能干嘛"></a>1）协程能干嘛</h4><blockquote><p>协程把异步编程放入库中来简化这类操作。程序逻辑在协程中顺序表述，而底层的库会将其转换为异步操作。库会将相关的用户代码打包成回调，订阅相关事件，调度其执行到不同的线程（甚至不同的机器），而代码依然想顺序执行那么简单。</p></blockquote><p>这段话似乎没有那么容易理解。让我们直接来看代码吧</p><pre><code class="Kotlin">/*未使用协程*/sql.querySingle(&quot;SELECT id FROM example&quot;){  if(it.failed()){    context.response().end(&quot;{status:-1}&quot;)  }else{    contezt.response().end(&quot;{status:1,id:${it.result().getInteger(0)}&quot;)  }}/* 使用协程 */val result = sql.querySingle(&quot;SELECT id FROM example&quot;).awit()if(it.failed()){  context.response().end(&quot;{status:-1}&quot;)}else{  contezt.response().end(&quot;{status:1,id:${it.result().getInteger(0)}&quot;)}</code></pre><p>两者的区别显而易见。在使用了协程之后我们能够将异步的代码转变为“同步”的代码。熟悉的赋值，没有了lambda参数，代码的执行顺序一下子就变得非常清晰了。这就是协程的作用</p><h4 id="2-协程怎么用"><a href="#2-协程怎么用" class="headerlink" title="2) 协程怎么用"></a>2) 协程怎么用</h4><p>Kotlin的文档<code>http://kotlinlang.org/docs/reference/coroutines.html</code>中，对于协程的使用有非常详细的说明。这里就只提供一种代码。<br>协程不是什么地方都能用的。我们需要一个launch来启动协程运行的上下文</p><pre><code class="Kotlin">fun Async(block:suspend ()-&gt;Unit){    block.startCoroutine(object : Continuation&lt;Unit&gt; {        override val context: CoroutineContext            get() = EmptyCoroutineContext        override fun resumeWithException(exception: Throwable) {            exception.printStackTrace()        }        override fun resume(value: Unit) {}    })}</code></pre><p>有了启动代码还是不能直接使用Vert.x的异步API，我们需要将API做一些转换</p><pre><code class="Kotlin">/* 柯理化 */fun AsyncSQLClient.querySingleWithParamsCurry(query:String,json:JsonArray)      =fun(handler:Handler&lt;AsyncResult&lt;JsonArray&gt;&gt;)      = this.querySingleWithParams(query,json,handler)</code></pre><p>在完成了柯理化之后，我们还需要提供一个awit方法</p><pre><code class="Kotlin">suspend fun &lt;T,R&gt; ((Handler&lt;T&gt;)-&gt;R).awit():T= suspendCoroutine{ con-&gt;    this(Handler {        con.resume(it)    })}</code></pre><p>在完成了上述代码过程之后，我们就可以使用协程了</p><pre><code class="Kotlin">router.route(&quot;/login/:username/:password&quot;).handler{  if(it.session().get&lt;String&gt;(&quot;username&quot;)==&quot;admin&quot;){    it.response().end(&quot;{status:1,msg:\&quot;You have logged in \&quot;}&quot;)    return@handler  }  val username = it.request().getParam(&quot;username&quot;)  val password = it.request().getParam(&quot;password&quot;)  Async{    val result = sqlClient.querySingleWithParamsCurry(&quot;SELECT id,level FROM user WHERE username=? and password=?&quot;,JsonArray(username,password)).awit()    if(result.failed() || result.result()==null){      it.response().end(&quot;{status:-1}&quot;)    }else{      it.session().put(&quot;username&quot;,username)      it.session().put(&quot;uid&quot;,result.result().getInteger(0))      it.session().put(&quot;level&quot;,result.result().getInteger(1))      it.response().end(&quot;{status:0}&quot;)    }  }}</code></pre><h4 id="3-协程本质"><a href="#3-协程本质" class="headerlink" title="3)协程本质"></a>3)协程本质</h4><blockquote><p>协程的底层实现就是个状态机</p></blockquote><p>想要把Kotlin中的协程引入现在的Java中是不可能的，协程是一种依赖编译器支持的语法糖。在上面这个例子中，Async内的代码经过编译之后会大致变成这个样子</p><pre><code class="Kotlin">fun afunction(status:Int=0,result:AsyncResult&lt;JsonArray&gt;?=null):Unit{  when(status){    0-&gt;{      sqlClient.querySingleWithParamsCurry(&quot;SELECT id,level FROM user WHERE username=? and password=?&quot;,JsonArray(username,password))({afunction(1,it)})    }    1-&gt;{      if(result.failed() || result.result()==null){        it.response().end(&quot;{status:-1}&quot;)      }else{        it.session().put(&quot;username&quot;,username)        it.session().put(&quot;uid&quot;,result.result().getInteger(0))        it.session().put(&quot;level&quot;,result.result().getInteger(1))        it.response().end(&quot;{status:0}&quot;)      }    }  }}</code></pre><p>这段代码并不准确，但是编译器的意图大致就是这样的。最终我们看到，该异步的还是异步了，只是编译器替我们做了许多事情，让我们的代码看起来像是同步的而已。</p><h2 id="3-来个注册"><a href="#3-来个注册" class="headerlink" title="3.来个注册"></a><strong>3.来个注册</strong></h2><p>在写完了异步的痛处与Kotlin中针对异步问题的处理后，我们来写一个用于注册的路由吧。注册与登录在代码方面差不了太多，唯一要注意的就是，SQLClient为INSERT、UPDATE、DELETE提供了与SELECT不同的方法。</p><pre><code class="Kotlin">AsyncSQLClient.updateWithParams(&quot;INSERT INTO example (a,b,c) VALUES (?,?,?)&quot;,JsonArray(a,b,c)){/* Do some */}</code></pre><p>乍看与SELECT中唯一的不同就是<code>query</code>变成了<code>update</code>。但实际上除了这一点，函数接收的Handler也不一样。之前query接收的参数是<code>Handler&lt;AsyncResult&lt;ResultSet&gt;&gt;</code>,而update接收的参数却是 <code>Handler&lt;AsyncResult&lt;UpdateResult&gt;&gt;</code> 。这个UpdateResult接口提供了两个比较重要的方法，一个是getUpdated(),这个方法返回一个更新的条数。而另一个getKeys()则返回所有生成的主键。这一点在插入有父子关系的表时会非常的有用。</p><pre><code class="Kotlin">/* 注册部分代码 */router.route(&quot;/register/:email/:username/:password/&quot;).handler{  val username = it.request().getParam(&quot;username&quot;)  val email = it.request().getParam(&quot;email&quot;)  val password = it.request().getParam(&quot;passwrd&quot;)  if(username==null || email==null || password==null){    it.response().end(&quot;{status:-1}&quot;)    return@handler  }  Async{    val result = sqlClient.updateWithParamsCurry(&quot;INSERT INTO user (email,username,password) VALUES (?,?,?)&quot;,JsonArray(email,username,password)).awit()    if(result.failed() || result.result().updated==0){      it.response().end(&quot;{status:-1}&quot;)    }else{      it.response().end(&quot;{status:1}&quot;)    }  }}</code></pre><p>非常简单，注册的部分也就完成了。</p><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4.小结"></a><strong>4.小结</strong></h2><p>也许Spring中Java是最好的选择，但是在Vert.x中Java可以说是一无是处了。在Kotlin中使用协程是一件非常愉快的事情，尽管到现在为止，Kotlin标准库的协程部分还是带着“实验性”的名称，而且偶尔会出现编译期的bug，但是相信在(可能)明年的Kotlin1.3中，协程会去掉“实验性”的标志，并变得更加完善。</p>]]></content>
      
      
        <tags>
            
            <tag> Vert.x </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Vert.x后端漫游指南(2)</title>
      <link href="/2018/07/02/Vert-x%E5%90%8E%E7%AB%AF%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8D%97-2/"/>
      <url>/2018/07/02/Vert-x%E5%90%8E%E7%AB%AF%E6%BC%AB%E6%B8%B8%E6%8C%87%E5%8D%97-2/</url>
      <content type="html"><![CDATA[<h2 id="1-前情提要"><a href="#1-前情提要" class="headerlink" title="1.前情提要"></a><strong>1.前情提要</strong></h2><p>上一篇我们已经学会了怎么实现一个最简单的Http服务端。这一篇我们会介绍怎么写一个用于登录的API。</p><h2 id="2-路由"><a href="#2-路由" class="headerlink" title="2.路由"></a><strong>2.路由</strong></h2><p>或许你们已经看过了HttpServerRequest这个接口，并且发现了这个接口中有一个返回String的方法叫做absoluteURI。稍微想一想就能发现，其实只需要对这个absoluteURI的返回值进行一些正则匹配，我们就能实现路由的功能。在实现了路由之后，我们还可以通过getParam方法获取到请求的参数。所以，如果只是做一个Demo，我们甚至不需要Vert.x的web扩展。<br>但是我们都是要干一番大事业的对吧。所以在这里我们要引入io.vertx.ext.web.Router。这个接口的名称已经够说明问题了，它能让我们建立像express中提供的路由。那么让我们来创建第一个路由吧</p><pre><code class="Kotlin">import io.vertx.ext.web.Routerimport io.vertx.core.Vertxfun main(args:Array&lt;String&gt;){  val vertx = Vertx.vertx()  ///////////////////Add Code here//////////////////////  val router = Router.router(vertx)  router.route(&quot;/login/:username/:password&quot;).handler{    val username = it.request().getParam(&quot;username&quot;)    val password = it.request().getParam(&quot;password&quot;)    if(username==&quot;admin&quot; &amp;&amp; password=&quot;admin123&quot;){      it.response().end(&quot;{status:0}&quot;)    }else{      it.response().end(&quot;{status:-1}&quot;)    }  }  //////////////////////////////////////////////////////  vertx.createHttpServer().requestHandler{    router.accept(it)  }.listen(80){    if(it.failed())      it.cause.printStackTrace()    else      println(&quot;Listening on 80&quot;)  }}</code></pre><p>这样我们就创建好了一个登录路由。这个路由接受两个参数，分别是username和password，用户在请求的时候大致是这样的<a href="http://example.com/login/admin/admin123" target="_blank" rel="noopener">http://example.com/login/admin/admin123</a> 。如果你对http协议比较熟悉的话，你可能会更加习惯<a href="http://example.com/login?username=admin&amp;password=admin123" target="_blank" rel="noopener">http://example.com/login?username=admin&amp;password=admin123</a> 这样的写法。其实这两者在Vert.x中是一样的。都可以通过</p><pre><code class="Kotlin">request.getParam(&quot;param name&quot;)</code></pre><p>这样的方式来获取，只不过前者需要在创建路由的时候设定好参数的名称以及位置，而后者的参数名称只在handler中出现。近几年越来越流行使用第一种方式，确实这样的api会更加的简洁，同时也不用把参数名称暴露在url中多少起了点保密的作用。<br>除了创建一个路由之外，我们还修改了requestHandler中的代码。我们将本来的<br><code>response().end(&quot;......&quot;)</code>换成了<code>router.accept(it)</code> 。相信这部分也非常的好理解，我们要让我们的router参与到HttpServer的处理中来，于是Router就提供了accept这个方法，它接收一个HttpServerRequest参数，在经过许多内部处理之后将一个包装好的RoutingContext传给我们的handler。这里其实还有另一种写法</p><pre><code class="Kotlin">vertx.createHttpServer.requestHandler(router::accept).listen(80)</code></pre><p>当然，这只是Kotlin的一点小技巧，似乎在Java8里也有类似的写法。</p><h2 id="3-更完整的登录"><a href="#3-更完整的登录" class="headerlink" title="3.更完整的登录"></a><strong>3.更完整的登录</strong></h2><p>路由在使用的过程中最核心的部分就是它的RoutingContext，这个Context把完全囊括了后端所需要的所有东西。对于用户的请求，我们可以通过request()获取，当我们想响应用户的时候，我们可以调用response()，而对于Cookie和Session，RoutingContext也为他们提供了相应的方法。<br>现在就让我们把这个登录做的更加完善一点。我们都知道，一个正常的登录过程中，服务端应该在用户登录之后保存一个session，并给用户一个Cookie，这两者就是一个键值对的关系。登录成功之后用户发送的每个请求都会带着这个Cookie，而服务端就通过这个Cookie去查询它对应的数据，比如说:用户名，用户id，用户权限等。<br>在使用Session之前，我们需要添加一点代码来初始化一些东西</p><pre><code class="Kotlin">val store = LocalSessionStore.create(vertx)router.route().handler(CookieHandler.create())router.route().handler(SessionHandler.create(store))</code></pre><p>Cookie的部分非常简单，没有什么可说的。但是在创建SessionHandler的时候，我们发现它需要一个SessionStore参数。Vert.x提供了两种SessionStore，一种是我们使用的<em>LocalSessionStore</em>而另一种是<em>ClusteredSessionStore</em>。字面来看，一种是本地存储的Session，而另一种是集群存储的Session，两者的区别也就非常明显了。本地存储的Session只存储在一个Vertx实例中，而集群存储则可以在多个实例中共享Session。</p><pre><code class="Kotlin">//创建集群会话存储val store = ClusteredSessionStore.create(vertx, &quot;myclusteredapp3.sessionmap&quot;);</code></pre><p>本系列中不会涉及到集群有关的内容，尽管分布式集群也是Vert.x一个非常明显的优势，但是由于作者本人也没有参与过这类分布式项目，在这方面经验浅薄，只能等之后有机会接触了再做补充。<br>在创建完SessionStore和SessionHandler之后，我们就可以在自己的handler中处理Session了</p><pre><code class="Kotlin">router.route(&quot;/login/:username/:password&quot;).handler{  if(it.session().get&lt;String&gt;(&quot;username&quot;)==&quot;admin&quot;){    it.response().end(&quot;{status:1,msg:\&quot;You have logged in \&quot;}&quot;)    return@handler  }  val username = it.request().getParam(&quot;username&quot;)  val password = it.request().getParam(&quot;password&quot;)  if(username==&quot;admin&quot; &amp;&amp; password=&quot;admin123&quot;){    it.session().put(&quot;username&quot;,&quot;admin&quot;)    it.session().put(&quot;level&quot;,&quot;1&quot;)    it.response().end(&quot;{status:0}&quot;)  }else{    it.response().end(&quot;{status:-1}&quot;)  }}</code></pre><p>这样我们的登录api就可以判断用户是否已经登录。每当用户请求的时候，我们就会调用<code>it.session().get()</code>判断用户是否已经登录。而每当用户登录成功的时候，我们就将用户名和等级放入Session中。用于之后的权限控制。</p><h2 id="4-一个可以投入使用的登录"><a href="#4-一个可以投入使用的登录" class="headerlink" title="4.一个可以投入使用的登录"></a><strong>4.一个可以投入使用的登录</strong></h2><p>一个正常的登录不应该是这样的对不对，没有人会把用户名和密码写在代码里。这么说可能不太对，其实也是有一些情况下，我们也会见到把用户名密码写在代码里的情况，比如说什么asp大马，php小马(不知道现在这种东西现在还有没有了)之类的东西或者是不靠谱的外包团队。<br>那么抛开这些另类的情况，为了实现一个登录功能，我们得有个数据库对不对。假如说我们现在已经有一个注册页面了，那么用户注册后的信息都应该放在数据库里，而登录的过程就是读数据库的过程。<br>Vert.x提供了很多操作数据库的包。这个系列里我们选择使用<strong>vertx-mysql-postgresql-client</strong>作为我们与数据库交互的客户端，同时呢，我们选择Mysql作为数据库。如果你从来没有接触过数据库的操作，那么你可以把Mysql想象成一个开放着3306端口的Excel表格，它允许连接到这个端口并且登录成功的客户端通过sql语句增删改查表格中的数据。<br>那么首先，我们要让我<strong>vertx-mysql-client</strong>连接到Mysql上。</p><pre><code class="Kotlin">import io.vertx.ext.asyncsql.AsyncSQLClientimport io.vertx.ext.asyncsql.MySQLClientval sqlClient = MySQLClient.createShared(vertx,JsonObject(&quot;host&quot; to &quot;localhost&quot;        ,&quot;username&quot; to &quot;root&quot;        ,&quot;password&quot; to &quot;root&quot;        ,&quot;database&quot; to &quot;example&quot;))</code></pre><p>这样我们就创建了一个<em>sqlClient</em>，如果连接成功的话。<br>这是关于MysqlClient的详细配置</p><pre><code class="JSON">{  &quot;host&quot; : &lt;主机地址&gt;,  &quot;port&quot; : &lt;端口&gt;,  &quot;maxPoolSize&quot; : &lt;最大连接数&gt;,  &quot;username&quot; : &lt;用户名&gt;,  &quot;password&quot; : &lt;密码&gt;,  &quot;database&quot; : &lt;数据库名称&gt;,  &quot;charset&quot; : &lt;编码&gt;,  &quot;queryTimeout&quot; : &lt;查询超时时间-毫秒&gt;}</code></pre><p>当然我们也可创建一个NonShared的sqlClient，创建方法是一样的，并且在这种只有一个Vert.x实例的工程中，两者的效果也是一样的。<br>现在我们要把这个sqlClient放到我们的RouterHandler中。</p><pre><code class="Kotlin">router.route(&quot;/login/:username/:password&quot;).handler{  if(it.session().get&lt;String&gt;(&quot;username&quot;)==&quot;admin&quot;){    it.response().end(&quot;{status:1,msg:\&quot;You have logged in \&quot;}&quot;)    return@handler  }  val username = it.request().getParam(&quot;username&quot;)  val password = it.request().getParam(&quot;password&quot;)  sqlClient.querySingleWithParams(&quot;SELECT id,level FROM user WHERE username=? and password=?&quot;,JsonArray(username,password)){    if(it.failed() || it.result()==null){      it.response().end(&quot;{status:-1}&quot;)    }else{      it.session().put(&quot;username&quot;,username)      it.session().put(&quot;uid&quot;,it.result().getInteger(0))      it.session().put(&quot;level&quot;,it.result().getInteger(1))      it.response().end(&quot;{status:0}&quot;)    }  }}</code></pre><p>我们对判断部分做了点修改，使我们能够使用数据库中的数据。当查询到用户名和密码都与用户输入匹配的结果时，我们就将查询结果存入到session中。</p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5.小结"></a><strong>5.小结</strong></h2><p>这一篇算是比较详细的讲了怎么实现一个能够使用的登录API，当然也不是很全面。在Router里还有很多内容可以写，会看情况在之后补充。下一篇应该会继续讲MysqlClient的使用，然后把curd全部写一下。</p><pre><code class="Kotlin">//完整代码import io.vertx.ext.web.Routerimport io.vertx.core.Vertximport io.vertx.ext.asyncsql.AsyncSQLClientimport io.vertx.ext.asyncsql.MySQLClient//在本例中，sqlClient、vertx、router写在什么地方都无所谓。如果你用Java，请把他们放在他们应该在的地方val sqlClient = MySQLClient.createShared(vertx,JsonObject(&quot;host&quot; to &quot;localhost&quot;        ,&quot;username&quot; to &quot;root&quot;        ,&quot;password&quot; to &quot;root&quot;        ,&quot;database&quot; to &quot;example&quot;))fun main(args:Array&lt;String&gt;){  val vertx = Vertx.vertx()  val router = Router.router(vertx)  val store = LocalSessionStore.create(vertx)  router.route().handler(CookieHandler.create())  router.route().handler(SessionHandler.create(store))  router.route(&quot;/login/:username/:password&quot;).handler{    if(it.session().get&lt;String&gt;(&quot;username&quot;)==&quot;admin&quot;){      it.response().end(&quot;{status:1,msg:\&quot;You have logged in \&quot;}&quot;)      return@handler    }    val username = it.request().getParam(&quot;username&quot;)    val password = it.request().getParam(&quot;password&quot;)    sqlClient.querySingleWithParams(&quot;SELECT id,level FROM user WHERE username=? and password=?&quot;,JsonArray(username,password)){      if(it.failed() || it.result()==null){        it.response().end(&quot;{status:-1}&quot;)      }else{        it.session().put(&quot;username&quot;,username)        it.session().put(&quot;uid&quot;,it.result().getInteger(0))        it.session().put(&quot;level&quot;,it.result().getInteger(1))        it.response().end(&quot;{status:0}&quot;)      }    }  }  vertx.createHttpServer().requestHandler{    router.accept(it)  }.listen(80){    if(it.failed())      it.cause.printStackTrace()    else      println(&quot;Listening on 80&quot;)  }}</code></pre>]]></content>
      
      
        <tags>
            
            <tag> Vert.x </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Vert.x后端漫游指南（1）</title>
      <link href="/2018/07/01/Vert-x%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8/"/>
      <url>/2018/07/01/Vert-x%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<h2 id="1-为什么是Vert-x"><a href="#1-为什么是Vert-x" class="headerlink" title="1.为什么是Vert.x"></a><strong>1.为什么是Vert.x</strong></h2><p>如果你从来没有听说过Vert.x，不要觉得是自己孤陋寡闻或是被时代抛弃了。Vert.x是一个非常小众的服务端框架，我也举不出某个大厂商将Vert.x作为它们后端技术栈的例子，但是这并不能说明Vert.x不够优秀，Vert.x不火很大程度上是因为它没有那些惊世骇俗的噱头，同时它实在是太年轻了。<br>学习这样一个小众的框架往往是要付出许多代价的，无论是大段的报错信息还是连报错信息都没有的错误，小众的东西总是让我们费劲心思。好在Vert.x并不属于这一类的小众，Vert.x的文档非常详细(包括中文文档)，并且它的源码注释也非常符合规范，配合文档以及注释，想要学习这个框架还是非常容易的。<br>那么问题来了，在现在这个框架爆炸的时代，我们为什么还要学习Vert.x呢？是啊，现在的框架是真的多，好像不管是什么样的语言都可以来写后端服务了，js有express，python有django，go、java、ruby就更不用说了。那Vert.x到底有什么优势呢？  </p><h4 id="优势"><a href="#优势" class="headerlink" title="优势:"></a>优势:</h4><ul><li><em>运行在JVM上</em><br>也许你不认为运行在JVM上会是一个框架的优势，毕竟JVM上已经有许多非常成熟的解决方案了，大名鼎鼎的Spring，J2EE，这样一个不出名的框架要怎么与这些老牌强者抗衡，但是Vert.x就是可以，因为它与众不同。运行在JVM上让它可以很轻松的利用Java庞大的生态，各种工具，各种成熟的技术还有现在让许多框架头疼的多线程问题。</li><li><em>事件循环以及异步</em><br>如果你了解Netty的话，你对事件循环和异步一定不会陌生，并且我可以告诉你Vert.x的底层实现就是Netty。如果你从来没有听说过Netty那也没关系，我想你多半听说过nodejs，通俗的来说Vert.x就是运行在JVM上的Nodejs。他们都有一个Eventloop，他们的所有API都是异步的，他们都遵守”Don’t call us,we’ll call you”的原则。只不过Vert.x更加自由，更加安全。异步很大的一个好处是将逻辑与I/O分离，逻辑的部分干逻辑的事，I/O的部分干I/O的事，因为I/O往往是耗时严重的，所以等到I/O完成了自己的工作后再来召唤逻辑，而在I/O工作的时候逻辑就去做其他的事情，这样两方都不会有干等着的时候。</li><li><em>多语言支持</em><br>JVM的优势在这种时候体现的淋漓尽致，除了JVM以外，还有哪个平台能够做到同时运行多种语言呢？.Net吗。Vert.x支持7种语言，Java(个人认为，Java是最不适合的。至少目前是这样，Java10应该会有所改观), JavaScript, Groovy, Ruby, Ceylon, Scala and Kotlin，并且这种支持不是简单的因为大家都能运行在JVM上。Vert.x为这些语言提供了属于他们自己的API。</li><li><em>不仅仅是Web,不仅仅是服务</em><br>没错，不仅仅是Web，Vert.x提供的不仅仅是对Web的支持。Vert.x是个插件化的框架，它的核心部分实际上非常的简练。这个核心提供了TCP，UDP甚至是DNS的服务端，也提供了简单的HTTP服务端。在这个核心的基础上，我们可以添加其他的插件，使这个框架能够胜任Web服务端的工作。如果我们碰巧需要一个客户端的话 —— 想象我们现在要开发一个代理工作，我们就同时需要一个服务端和一个客户端 —— 那Vert.x简直就是不二之选，DNSClient,HttpClient,NetClient,DatagramSocketClient，我们想要的它都能提供。</li></ul><p>那么同样的，任何事物都有好的与坏的，如果有某样东西完美了，那它为什么还会有竞争对手</p><h4 id="劣势"><a href="#劣势" class="headerlink" title="劣势:"></a>劣势:</h4><ul><li><em>上手困难</em><br>不是所有人都能轻松的理解异步的，特别是在java里有很多同步代码的情况下，比如JDBC，习惯了同步的人很容易一不小心就忘了自己在一个异步的世界里，然后阻塞了Eventloop,接着有幸看到Vert.x抛出的超时异常。没错，Vert.x是会检测运行时间的，如果某段代码超时了，你会看到一个非常醒目的异常。</li><li>没了  </li></ul><h2 id="2-跨出的一小步"><a href="#2-跨出的一小步" class="headerlink" title="2.跨出的一小步"></a><strong>2.跨出的一小步</strong></h2><p>说了这么多，不如来看一看怎么写一个简单的http服务端吧。这个入门应该会出一个系列，从第一个服务端程序到一个比较完整的后端。可能会涉及到一点后端渲染，但是其实我不太喜欢后端渲染的东西。前端渲染有很多好处，无论是CDN还是利用浏览器的缓存，前端渲染都能减轻服务器负担。<br>首先，我们需要Vert.x。这个可以在Vert.x的官方网站上获取到</p><blockquote><p><a href="https://vertx.io/download/" target="_blank" rel="noopener">https://vertx.io/download/</a></p></blockquote><p>官网甚至提供了一个构建Vert.x工程的工具</p><blockquote><p><a href="http://start.vertx.io/" target="_blank" rel="noopener">http://start.vertx.io/</a></p></blockquote><p>如果你不知道怎么配置的话，可以直接在这里开始。<br>在这个系列里，我可能不常使用Java，而更加倾向于使用Kotlin。因为Kotlin和Vert.x的契合度非常高，Kotlin提供的协程可以很好的解决一些因为异步导致的问题，并且Kotlin完全兼容Java的特点也让Kotlin在许多其他语言中脱颖而出。<br>那让我们来看一个最简单的Http服务端是怎么实现的。</p><pre><code class="Kotlin">import io.vertx.core.Vertxfun main(args:Array&lt;String&gt;){  val vertx = Vertx.vertx()  vertx.createHttpServer().requestHandler{    it.response().end(&quot;Welcome to our first Http Server!&quot;)  }.listen(80){    if(it.failed())      it.cause.printStackTrace()    else      println(&quot;Listening on 80&quot;)  }}</code></pre><p>这是用Kotlin实现一个简单HttpServer的版本。如果你从来没有接触过Kotlin的话，你只要记住一点func{}等于func({}),函数的最后一个lambda参数是可以放到小括号外面去的。然后对于只有一个参数的lambda，这个参数默认的名称叫做it。<br>我们可以看看这段代码到底做了什么。首先，我们得到了一个vertx对象，这个vertx是一切的起源。接着我们调用了createHttpServer方法，创建了一个Server。在创建完Server之后我们为它添加了一个handler，可以看到，Vert.x的API大多是流式的，写起来非常漂亮，fp的美感。在Kotlin里，这个handler表现为一个lambda，实际上这个requestHandler所需要的参数是一个Handler<httpserverrequest>接口，所以在Java里，写法就变成了</httpserverrequest></p><pre><code class="Java">vertx.createHttpServer().requestHandler(new Handler&lt;HttpServerRequest&gt;(){  @Override  void handle(HttpServerRequest req){    req.response().end(&quot;Welcome to our first Http Server!&quot;);  }});</code></pre><p>当然这种写法比较过时，java8已经加入了lambda，但是为了更加清晰一点，这里我把这种原始的版本表示出来。<br>这个handler是在服务端启动后，每当有用户访问我们的服务端，服务端就会返回一个欢迎词，就像nginx的默认页面一样。同样的，listen也是差不多的过程，第一个参数是监听的端口，第二个参数则是用来处理监听结果的handler，这个handler在端口成功打开或是打开失败的时候被调用，所以我们可以知道我们的服务端有没有成功运行。<br>其实这里异步的特点就已经有所体现了，我们没有等待用户访问，也没有等待端口打开，所有的一切都是异步的。当有结果的时候，Vert.x就会来调用我们设定的handler，而当没有结果的时候，Evnetloop就会在那里自己循环，只要我们不写阻塞代码，Eventloop就永远不会停止循环。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><em>小结</em></h2><p>第一篇就大概介绍一下Vert.x的理念，实际上Vert.x的许多特性比介绍的要复杂的多，有兴趣的人可以去看中问文档，里面有讲关于Verticle的，关于分布式的，以及一些类似于热部署的。这里写的一个例子也非常的简单，但是如果你从来没有接触过异步，这对你来说可能是个挑战。你得明白，为什么这段代码不是按照顺序执行的，以及什么是lambda(这个不是非常重要，lambda只是一种表现形式而已，我们实例化一个接口也完全可以实现同样的功能)。<br>下一篇应该是会讲请求的处理，get的和post的，以及Router这个扩展。</p>]]></content>
      
      
        <tags>
            
            <tag> Vert.x </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
